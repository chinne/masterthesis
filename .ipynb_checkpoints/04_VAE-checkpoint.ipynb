{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from src.models import vae, TESTVAE\n",
    " \n",
    "from src.common.helperfunctions import *\n",
    "from src.common.accuracy_XGboost import *\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'data/raw/creditcard.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = []\n",
    "feature_cols = []\n",
    "label_col = [i for i in df.columns if 'Class' in i]\n",
    "feature_cols = [i for i in df.columns if i not in label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chinne/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/chinne/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "mxs = MinMaxScaler()\n",
    "train.iloc[:,:] = mxs.fit_transform(train.iloc[:,:].values)\n",
    "test.iloc[:,:] = mxs.transform(test.iloc[:,:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "      <td>227845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.548593</td>\n",
       "      <td>0.958309</td>\n",
       "      <td>0.767254</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>0.251866</td>\n",
       "      <td>0.765723</td>\n",
       "      <td>0.263014</td>\n",
       "      <td>0.265362</td>\n",
       "      <td>0.785381</td>\n",
       "      <td>0.561763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561483</td>\n",
       "      <td>0.509974</td>\n",
       "      <td>0.665436</td>\n",
       "      <td>0.382205</td>\n",
       "      <td>0.577852</td>\n",
       "      <td>0.425417</td>\n",
       "      <td>0.238396</td>\n",
       "      <td>0.313129</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.274830</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>0.017480</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>0.062764</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.013440</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.012750</td>\n",
       "      <td>0.046285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>0.033836</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.081584</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>0.078806</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.041548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.313446</td>\n",
       "      <td>0.942666</td>\n",
       "      <td>0.760949</td>\n",
       "      <td>0.903290</td>\n",
       "      <td>0.214283</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.255292</td>\n",
       "      <td>0.261992</td>\n",
       "      <td>0.783150</td>\n",
       "      <td>0.534633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557792</td>\n",
       "      <td>0.484709</td>\n",
       "      <td>0.663038</td>\n",
       "      <td>0.334413</td>\n",
       "      <td>0.560066</td>\n",
       "      <td>0.371956</td>\n",
       "      <td>0.236687</td>\n",
       "      <td>0.312049</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.490225</td>\n",
       "      <td>0.958599</td>\n",
       "      <td>0.767955</td>\n",
       "      <td>0.923662</td>\n",
       "      <td>0.251001</td>\n",
       "      <td>0.765348</td>\n",
       "      <td>0.260256</td>\n",
       "      <td>0.265607</td>\n",
       "      <td>0.785624</td>\n",
       "      <td>0.559597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561002</td>\n",
       "      <td>0.510287</td>\n",
       "      <td>0.665276</td>\n",
       "      <td>0.387727</td>\n",
       "      <td>0.578754</td>\n",
       "      <td>0.416952</td>\n",
       "      <td>0.238430</td>\n",
       "      <td>0.313355</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.806201</td>\n",
       "      <td>0.980643</td>\n",
       "      <td>0.775741</td>\n",
       "      <td>0.939779</td>\n",
       "      <td>0.284806</td>\n",
       "      <td>0.769831</td>\n",
       "      <td>0.267002</td>\n",
       "      <td>0.268832</td>\n",
       "      <td>0.788899</td>\n",
       "      <td>0.586985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564479</td>\n",
       "      <td>0.534635</td>\n",
       "      <td>0.667635</td>\n",
       "      <td>0.441496</td>\n",
       "      <td>0.597578</td>\n",
       "      <td>0.464785</td>\n",
       "      <td>0.240599</td>\n",
       "      <td>0.314716</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  227845.000000  227845.000000  227845.000000  227845.000000   \n",
       "mean        0.548593       0.958309       0.767254       0.920235   \n",
       "std         0.274830       0.033270       0.017480       0.028841   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.313446       0.942666       0.760949       0.903290   \n",
       "50%         0.490225       0.958599       0.767955       0.923662   \n",
       "75%         0.806201       0.980643       0.775741       0.939779   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  227845.000000  227845.000000  227845.000000  227845.000000   \n",
       "mean        0.251866       0.765723       0.263014       0.265362   \n",
       "std         0.062764       0.009342       0.013440       0.007575   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.214283       0.761079       0.255292       0.261992   \n",
       "50%         0.251001       0.765348       0.260256       0.265607   \n",
       "75%         0.284806       0.769831       0.267002       0.268832   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  227845.000000  227845.000000  ...  227845.000000  227845.000000   \n",
       "mean        0.785381       0.561763  ...       0.561483       0.509974   \n",
       "std         0.012750       0.046285  ...       0.011810       0.033836   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.783150       0.534633  ...       0.557792       0.484709   \n",
       "50%         0.785624       0.559597  ...       0.561002       0.510287   \n",
       "75%         0.788899       0.586985  ...       0.564479       0.534635   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  227845.000000  227845.000000  227845.000000  227845.000000   \n",
       "mean        0.665436       0.382205       0.577852       0.425417   \n",
       "std         0.009313       0.081584       0.029288       0.078806   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.663038       0.334413       0.560066       0.371956   \n",
       "50%         0.665276       0.387727       0.578754       0.416952   \n",
       "75%         0.667635       0.441496       0.597578       0.464785   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 V27            V28         Amount          Class  \n",
       "count  227845.000000  227845.000000  227845.000000  227845.000000  \n",
       "mean        0.238396       0.313129       0.003444       0.001729  \n",
       "std         0.009681       0.006692       0.009923       0.041548  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.236687       0.312049       0.000218       0.000000  \n",
       "50%         0.238430       0.313355       0.000856       0.000000  \n",
       "75%         0.240599       0.314716       0.003001       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Class = train[train.Class == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chinne/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:635: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/home/chinne/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "train.loc[:,'Amount'] = sc.fit_transform(train.Amount.values.reshape(-1, 1))\n",
    "test_X.loc[:,'Amount'] = sc.transform(test_X.Amount.values.reshape(-1, 1))\n",
    "train.drop('Time',axis=1, inplace=True)\n",
    "test_X.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = []\n",
    "feature_cols = []\n",
    "label_col = [i for i in train.columns if 'Class' in i]\n",
    "feature_cols = [i for i in train.columns if i not in label_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chinne/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_Class.drop('Class', axis = 1,inplace=True)\n",
    "# train_Class.drop('Time', axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>394.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.460459</td>\n",
       "      <td>0.882117</td>\n",
       "      <td>0.804668</td>\n",
       "      <td>0.789376</td>\n",
       "      <td>0.454106</td>\n",
       "      <td>0.745540</td>\n",
       "      <td>0.248580</td>\n",
       "      <td>0.232283</td>\n",
       "      <td>0.792952</td>\n",
       "      <td>0.453685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583807</td>\n",
       "      <td>0.573374</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>0.664096</td>\n",
       "      <td>0.367891</td>\n",
       "      <td>0.579340</td>\n",
       "      <td>0.435710</td>\n",
       "      <td>0.242968</td>\n",
       "      <td>0.314856</td>\n",
       "      <td>0.004352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.278781</td>\n",
       "      <td>0.110547</td>\n",
       "      <td>0.042736</td>\n",
       "      <td>0.130531</td>\n",
       "      <td>0.125469</td>\n",
       "      <td>0.035252</td>\n",
       "      <td>0.017741</td>\n",
       "      <td>0.041740</td>\n",
       "      <td>0.066827</td>\n",
       "      <td>0.103345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>0.056664</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.024285</td>\n",
       "      <td>0.070422</td>\n",
       "      <td>0.046032</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>0.032057</td>\n",
       "      <td>0.010831</td>\n",
       "      <td>0.009317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.439247</td>\n",
       "      <td>0.678603</td>\n",
       "      <td>0.327953</td>\n",
       "      <td>0.193714</td>\n",
       "      <td>0.616903</td>\n",
       "      <td>0.198611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536310</td>\n",
       "      <td>0.193973</td>\n",
       "      <td>0.095452</td>\n",
       "      <td>0.379490</td>\n",
       "      <td>0.108959</td>\n",
       "      <td>0.309503</td>\n",
       "      <td>0.237611</td>\n",
       "      <td>0.063405</td>\n",
       "      <td>0.275190</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.238237</td>\n",
       "      <td>0.858256</td>\n",
       "      <td>0.780714</td>\n",
       "      <td>0.760412</td>\n",
       "      <td>0.359170</td>\n",
       "      <td>0.733984</td>\n",
       "      <td>0.237958</td>\n",
       "      <td>0.218303</td>\n",
       "      <td>0.783666</td>\n",
       "      <td>0.397028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578364</td>\n",
       "      <td>0.562816</td>\n",
       "      <td>0.485348</td>\n",
       "      <td>0.660343</td>\n",
       "      <td>0.322935</td>\n",
       "      <td>0.559571</td>\n",
       "      <td>0.384008</td>\n",
       "      <td>0.237973</td>\n",
       "      <td>0.310967</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.438192</td>\n",
       "      <td>0.920690</td>\n",
       "      <td>0.796274</td>\n",
       "      <td>0.822133</td>\n",
       "      <td>0.440937</td>\n",
       "      <td>0.756893</td>\n",
       "      <td>0.248623</td>\n",
       "      <td>0.247029</td>\n",
       "      <td>0.792052</td>\n",
       "      <td>0.469722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583163</td>\n",
       "      <td>0.570970</td>\n",
       "      <td>0.512663</td>\n",
       "      <td>0.664301</td>\n",
       "      <td>0.373181</td>\n",
       "      <td>0.583192</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>0.247911</td>\n",
       "      <td>0.315899</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.727155</td>\n",
       "      <td>0.954272</td>\n",
       "      <td>0.816778</td>\n",
       "      <td>0.877708</td>\n",
       "      <td>0.533033</td>\n",
       "      <td>0.767393</td>\n",
       "      <td>0.258487</td>\n",
       "      <td>0.259373</td>\n",
       "      <td>0.804385</td>\n",
       "      <td>0.528544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588796</td>\n",
       "      <td>0.582366</td>\n",
       "      <td>0.538727</td>\n",
       "      <td>0.669426</td>\n",
       "      <td>0.423414</td>\n",
       "      <td>0.603487</td>\n",
       "      <td>0.491854</td>\n",
       "      <td>0.257430</td>\n",
       "      <td>0.320679</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.985856</td>\n",
       "      <td>0.994520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963103</td>\n",
       "      <td>0.788963</td>\n",
       "      <td>0.840408</td>\n",
       "      <td>0.328111</td>\n",
       "      <td>0.298443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897985</td>\n",
       "      <td>0.746612</td>\n",
       "      <td>0.529304</td>\n",
       "      <td>0.701859</td>\n",
       "      <td>0.873881</td>\n",
       "      <td>0.311934</td>\n",
       "      <td>0.349233</td>\n",
       "      <td>0.082747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time          V1          V2          V3          V4          V5  \\\n",
       "count  394.000000  394.000000  394.000000  394.000000  394.000000  394.000000   \n",
       "mean     0.460459    0.882117    0.804668    0.789376    0.454106    0.745540   \n",
       "std      0.278781    0.110547    0.042736    0.130531    0.125469    0.035252   \n",
       "min      0.002350    0.439247    0.678603    0.327953    0.193714    0.616903   \n",
       "25%      0.238237    0.858256    0.780714    0.760412    0.359170    0.733984   \n",
       "50%      0.438192    0.920690    0.796274    0.822133    0.440937    0.756893   \n",
       "75%      0.727155    0.954272    0.816778    0.877708    0.533033    0.767393   \n",
       "max      0.985856    0.994520    1.000000    0.963103    0.788963    0.840408   \n",
       "\n",
       "               V6          V7          V8          V9  ...         V20  \\\n",
       "count  394.000000  394.000000  394.000000  394.000000  ...  394.000000   \n",
       "mean     0.248580    0.232283    0.792952    0.453685  ...    0.583807   \n",
       "std      0.017741    0.041740    0.066827    0.103345  ...    0.013042   \n",
       "min      0.198611    0.000000    0.345109    0.000000  ...    0.536310   \n",
       "25%      0.237958    0.218303    0.783666    0.397028  ...    0.578364   \n",
       "50%      0.248623    0.247029    0.792052    0.469722  ...    0.583163   \n",
       "75%      0.258487    0.259373    0.804385    0.528544  ...    0.588796   \n",
       "max      0.328111    0.298443    1.000000    0.703144  ...    0.698016   \n",
       "\n",
       "              V21         V22         V23         V24         V25         V26  \\\n",
       "count  394.000000  394.000000  394.000000  394.000000  394.000000  394.000000   \n",
       "mean     0.573374    0.510644    0.664096    0.367891    0.579340    0.435710   \n",
       "std      0.056664    0.064164    0.024285    0.070422    0.046032    0.077310   \n",
       "min      0.193973    0.095452    0.379490    0.108959    0.309503    0.237611   \n",
       "25%      0.562816    0.485348    0.660343    0.322935    0.559571    0.384008   \n",
       "50%      0.570970    0.512663    0.664301    0.373181    0.583192    0.429032   \n",
       "75%      0.582366    0.538727    0.669426    0.423414    0.603487    0.491854   \n",
       "max      1.000000    0.897985    0.746612    0.529304    0.701859    0.873881   \n",
       "\n",
       "              V27         V28      Amount  \n",
       "count  394.000000  394.000000  394.000000  \n",
       "mean     0.242968    0.314856    0.004352  \n",
       "std      0.032057    0.010831    0.009317  \n",
       "min      0.063405    0.275190    0.000000  \n",
       "25%      0.237973    0.310967    0.000039  \n",
       "50%      0.247911    0.315899    0.000357  \n",
       "75%      0.257430    0.320679    0.004049  \n",
       "max      0.311934    0.349233    0.082747  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Class.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = prepareDataset(train_Class, batch_size = 10, device = 'cpu', withLabel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset.features.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "====> Epoch: 0 Average loss: 19.8111\n",
      "====> Epoch: 1 Average loss: 19.9334\n",
      "====> Epoch: 2 Average loss: 19.5676\n",
      "====> Epoch: 3 Average loss: 19.0560\n",
      "====> Epoch: 4 Average loss: 19.5340\n",
      "====> Epoch: 5 Average loss: 19.4285\n",
      "====> Epoch: 6 Average loss: 20.0620\n",
      "====> Epoch: 7 Average loss: 19.8309\n",
      "====> Epoch: 8 Average loss: 19.7279\n",
      "====> Epoch: 9 Average loss: 19.6775\n",
      "====> Epoch: 10 Average loss: 19.6176\n",
      "====> Epoch: 11 Average loss: 19.5486\n",
      "====> Epoch: 12 Average loss: 19.4984\n",
      "====> Epoch: 13 Average loss: 19.3782\n",
      "====> Epoch: 14 Average loss: 19.4280\n",
      "====> Epoch: 15 Average loss: 19.4840\n",
      "====> Epoch: 16 Average loss: 19.4354\n",
      "====> Epoch: 17 Average loss: 19.5869\n",
      "====> Epoch: 18 Average loss: 19.5029\n",
      "====> Epoch: 19 Average loss: 19.6739\n",
      "It took  8.020713329315186\n"
     ]
    }
   ],
   "source": [
    "losses = TESTVAE.trainVAE(dataloader, num_epochs=20, data_dim = dataloader.dataset.features.size(1),feature_cols=feature_cols, embeddingDim=128, compressDims=(128, 128), decompressDims=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "tensor([9.6580e-01, 9.9383e-01, 7.5927e-01, 8.9755e-01, 2.1844e-01, 7.6154e-01,\n",
      "        2.5978e-01, 2.5876e-01, 7.8664e-01, 5.5578e-01, 6.2353e-01, 3.6487e-01,\n",
      "        6.9176e-01, 4.2019e-01, 5.8470e-01, 3.1363e-01, 5.0794e-01, 7.6583e-01,\n",
      "        6.5587e-01, 5.9636e-01, 5.8066e-01, 5.6613e-01, 5.4884e-01, 6.6754e-01,\n",
      "        4.6209e-01, 5.6690e-01, 4.0312e-01, 2.3888e-01, 3.1281e-01, 7.7653e-04])\n",
      "tensor([0.5435, 0.7660, 0.8431, 0.6693, 0.6553, 0.6978, 0.2385, 0.1789, 0.8331,\n",
      "        0.2985, 0.3005, 0.6455, 0.1118, 0.4575, 0.3551, 0.1423, 0.0922, 0.1040,\n",
      "        0.0281, 0.6548, 0.5783, 0.5789, 0.4937, 0.6726, 0.4713, 0.5556, 0.3579,\n",
      "        0.2144, 0.3084, 0.0015])\n",
      "tensor([2.5692e-01, 8.7985e-01, 8.0591e-01, 8.1937e-01, 4.2397e-01, 7.4375e-01,\n",
      "        2.5378e-01, 2.3054e-01, 7.9430e-01, 4.5811e-01, 4.7350e-01, 4.9495e-01,\n",
      "        4.5962e-01, 3.6993e-01, 4.0893e-01, 3.9006e-01, 2.3393e-01, 4.8159e-01,\n",
      "        3.4305e-01, 6.5295e-01, 5.7658e-01, 6.0498e-01, 5.0877e-01, 6.7088e-01,\n",
      "        3.6566e-01, 5.6104e-01, 3.8625e-01, 2.3398e-01, 3.1164e-01, 3.8924e-05])\n",
      "tensor([0.7510, 0.9169, 0.8013, 0.7946, 0.4112, 0.7584, 0.2455, 0.2651, 0.7886,\n",
      "        0.4867, 0.4707, 0.4785, 0.4795, 0.3589, 0.2761, 0.3753, 0.3741, 0.6918,\n",
      "        0.6663, 0.6042, 0.5773, 0.5609, 0.4905, 0.6678, 0.2859, 0.6042, 0.3685,\n",
      "        0.2485, 0.3065, 0.0141])\n",
      "tensor([0.2368, 0.9117, 0.8059, 0.8420, 0.4887, 0.7478, 0.2621, 0.2386, 0.7824,\n",
      "        0.4427, 0.5051, 0.5214, 0.4273, 0.3583, 0.3695, 0.3931, 0.2340, 0.4750,\n",
      "        0.3391, 0.6513, 0.5822, 0.6005, 0.5055, 0.6711, 0.3614, 0.5552, 0.4708,\n",
      "        0.2584, 0.3176, 0.0044])\n",
      "tensor([0.3679, 0.9474, 0.7664, 0.9444, 0.3140, 0.7640, 0.2732, 0.2733, 0.7839,\n",
      "        0.5435, 0.6150, 0.2305, 0.6811, 0.4637, 0.6466, 0.4972, 0.4326, 0.7295,\n",
      "        0.6841, 0.6542, 0.5894, 0.5670, 0.5455, 0.6707, 0.2773, 0.5739, 0.4200,\n",
      "        0.2369, 0.3119, 0.0113])\n",
      "tensor([0.1081, 0.7487, 0.8146, 0.6044, 0.7000, 0.6956, 0.2643, 0.1703, 0.7730,\n",
      "        0.3380, 0.2924, 0.8089, 0.1933, 0.5385, 0.3162, 0.3588, 0.1471, 0.2214,\n",
      "        0.1861, 0.7249, 0.5794, 0.5278, 0.5914, 0.6859, 0.3075, 0.4875, 0.4506,\n",
      "        0.2676, 0.2752, 0.0073])\n",
      "tensor([6.4123e-02, 9.2218e-01, 8.3029e-01, 7.1012e-01, 6.5121e-01, 7.5434e-01,\n",
      "        2.3432e-01, 2.1777e-01, 8.0717e-01, 3.1280e-01, 2.9491e-01, 1.0000e+00,\n",
      "        3.4470e-02, 4.1497e-01, 0.0000e+00, 2.5841e-01, 1.2286e-01, 2.8066e-01,\n",
      "        2.7537e-01, 5.3126e-01, 5.9617e-01, 5.8802e-01, 4.9704e-01, 6.5556e-01,\n",
      "        2.2531e-01, 6.7343e-01, 5.3829e-01, 2.8947e-01, 3.3563e-01, 3.8924e-05])\n",
      "tensor([6.7335e-02, 9.7391e-01, 8.1157e-01, 7.7675e-01, 5.8116e-01, 7.7324e-01,\n",
      "        2.3400e-01, 2.5719e-01, 7.8929e-01, 4.6881e-01, 5.1339e-01, 5.5705e-01,\n",
      "        4.1665e-01, 5.8255e-01, 3.2863e-01, 3.2918e-01, 4.1011e-01, 7.7855e-01,\n",
      "        7.4378e-01, 5.4089e-01, 5.8597e-01, 5.6658e-01, 5.1261e-01, 6.6856e-01,\n",
      "        3.2592e-01, 5.2676e-01, 5.0165e-01, 2.5351e-01, 3.1633e-01, 3.8924e-05])\n",
      "tensor([6.3711e-01, 9.9117e-01, 7.7412e-01, 9.1479e-01, 4.2871e-01, 7.6784e-01,\n",
      "        2.6202e-01, 2.6522e-01, 7.8354e-01, 5.8318e-01, 6.4420e-01, 2.5986e-01,\n",
      "        5.9950e-01, 5.7506e-01, 6.9888e-01, 2.2202e-01, 4.7825e-01, 7.2758e-01,\n",
      "        6.4613e-01, 4.3181e-01, 5.7660e-01, 5.5868e-01, 5.0112e-01, 6.6870e-01,\n",
      "        3.5305e-01, 5.7023e-01, 4.0422e-01, 2.3719e-01, 3.1209e-01, 3.8924e-05])\n",
      "tensor([0.5931, 0.9255, 0.8102, 0.8276, 0.5134, 0.7620, 0.2474, 0.2420, 0.7927,\n",
      "        0.4157, 0.4495, 0.7028, 0.2857, 0.5808, 0.2948, 0.1200, 0.2502, 0.3927,\n",
      "        0.4159, 0.5237, 0.5903, 0.5798, 0.5415, 0.6575, 0.3238, 0.5992, 0.4578,\n",
      "        0.2593, 0.3178, 0.0000])\n",
      "tensor([0.9068, 0.9561, 0.7688, 0.9032, 0.2316, 0.7712, 0.2579, 0.2737, 0.7831,\n",
      "        0.5705, 0.5768, 0.2377, 0.7231, 0.5349, 0.5850, 0.2796, 0.4527, 0.7520,\n",
      "        0.6674, 0.5593, 0.5845, 0.5610, 0.4985, 0.6726, 0.4307, 0.5534, 0.3849,\n",
      "        0.2389, 0.3153, 0.0073])\n",
      "tensor([2.0044e-01, 9.6396e-01, 7.8519e-01, 8.7081e-01, 4.1346e-01, 7.6178e-01,\n",
      "        2.5644e-01, 2.5149e-01, 7.9263e-01, 4.7559e-01, 5.4610e-01, 4.5191e-01,\n",
      "        5.3863e-01, 3.4231e-01, 4.6693e-01, 3.4324e-01, 4.0612e-01, 5.8308e-01,\n",
      "        6.3004e-01, 5.5362e-01, 5.8377e-01, 5.6904e-01, 5.0330e-01, 6.6071e-01,\n",
      "        2.7852e-01, 6.2325e-01, 4.6272e-01, 2.5167e-01, 3.1932e-01, 7.3800e-04])\n",
      "tensor([2.4877e-01, 8.8905e-01, 7.7742e-01, 8.2359e-01, 4.7162e-01, 7.6463e-01,\n",
      "        2.3454e-01, 2.1894e-01, 8.0275e-01, 4.3554e-01, 4.3797e-01, 6.5865e-01,\n",
      "        3.4964e-01, 3.0754e-01, 2.8495e-01, 3.4784e-01, 1.8136e-01, 3.3881e-01,\n",
      "        3.2915e-01, 7.6873e-01, 5.8089e-01, 5.7810e-01, 5.1774e-01, 6.5032e-01,\n",
      "        3.1783e-01, 5.6079e-01, 4.0812e-01, 2.8416e-01, 3.2350e-01, 3.8924e-05])\n",
      "tensor([5.4610e-01, 5.0881e-01, 9.4133e-01, 3.4559e-01, 6.4664e-01, 6.4526e-01,\n",
      "        2.5067e-01, 7.5298e-02, 6.6268e-01, 1.6268e-01, 6.0280e-02, 5.4812e-01,\n",
      "        3.0497e-01, 3.9385e-01, 5.1404e-01, 1.5005e-01, 2.3279e-01, 3.6902e-01,\n",
      "        2.7495e-01, 5.1896e-01, 6.1021e-01, 4.2033e-01, 6.7148e-01, 6.7875e-01,\n",
      "        4.1657e-01, 5.3648e-01, 2.6756e-01, 6.3405e-02, 2.8624e-01, 3.8924e-05])\n",
      "tensor([0.2633, 0.9753, 0.7678, 0.9136, 0.3182, 0.7670, 0.2649, 0.2653, 0.7870,\n",
      "        0.5862, 0.5974, 0.2268, 0.6828, 0.3628, 0.5996, 0.3615, 0.4583, 0.7640,\n",
      "        0.6597, 0.5400, 0.5804, 0.5561, 0.4627, 0.6635, 0.2547, 0.6035, 0.3514,\n",
      "        0.2395, 0.3144, 0.0041])\n",
      "tensor([0.8274, 0.9661, 0.7818, 0.9109, 0.3763, 0.7777, 0.2640, 0.2732, 0.7839,\n",
      "        0.4902, 0.6412, 0.1841, 0.6951, 0.4837, 0.6507, 0.1884, 0.4612, 0.7079,\n",
      "        0.6054, 0.4464, 0.5774, 0.5632, 0.5273, 0.6662, 0.4363, 0.5372, 0.3923,\n",
      "        0.2406, 0.3151, 0.0000])\n",
      "tensor([5.8481e-01, 9.3340e-01, 7.5572e-01, 9.1911e-01, 2.9913e-01, 8.4041e-01,\n",
      "        2.0842e-01, 2.0822e-01, 7.8060e-01, 6.4573e-01, 6.6210e-01, 3.6667e-01,\n",
      "        6.4872e-01, 3.9223e-01, 7.6180e-01, 2.5879e-01, 3.9764e-01, 7.7234e-01,\n",
      "        5.5577e-01, 4.3433e-01, 5.6475e-01, 5.8019e-01, 4.5127e-01, 4.2809e-01,\n",
      "        2.6316e-01, 3.7938e-01, 3.2859e-01, 2.5467e-01, 3.2175e-01, 3.5810e-05])\n",
      "tensor([0.6325, 0.9413, 0.8026, 0.8149, 0.5550, 0.7637, 0.2640, 0.2505, 0.7992,\n",
      "        0.4451, 0.5054, 0.5646, 0.3739, 0.5246, 0.3999, 0.2508, 0.3421, 0.6076,\n",
      "        0.6237, 0.7042, 0.5929, 0.5686, 0.4777, 0.6699, 0.2936, 0.5836, 0.4958,\n",
      "        0.2583, 0.3198, 0.0072])\n",
      "tensor([0.4055, 0.9508, 0.7793, 0.8588, 0.3957, 0.7520, 0.2467, 0.2469, 0.7936,\n",
      "        0.4857, 0.4990, 0.5626, 0.5093, 0.3226, 0.4203, 0.3768, 0.3452, 0.5329,\n",
      "        0.5601, 0.5861, 0.5898, 0.5738, 0.4972, 0.6603, 0.4136, 0.6119, 0.3739,\n",
      "        0.2569, 0.3225, 0.0088])\n",
      "tensor([5.2477e-01, 9.1743e-01, 8.0670e-01, 8.7611e-01, 3.1255e-01, 7.6837e-01,\n",
      "        2.8232e-01, 2.4643e-01, 6.6992e-01, 7.0314e-01, 6.2656e-01, 3.0801e-01,\n",
      "        6.1890e-01, 5.4204e-01, 5.8282e-01, 2.6054e-01, 4.5684e-01, 8.2764e-01,\n",
      "        7.8440e-01, 5.1792e-01, 5.5747e-01, 7.2278e-01, 3.9551e-01, 6.9046e-01,\n",
      "        3.9817e-01, 4.9195e-01, 3.1187e-01, 2.3472e-01, 3.1031e-01, 2.7208e-04])\n",
      "tensor([2.7678e-01, 9.4322e-01, 7.8192e-01, 9.4348e-01, 3.2558e-01, 7.7251e-01,\n",
      "        2.5564e-01, 2.7057e-01, 7.8539e-01, 5.0793e-01, 6.0639e-01, 2.9368e-01,\n",
      "        6.8684e-01, 4.1986e-01, 6.0677e-01, 3.4241e-01, 4.7741e-01, 7.4862e-01,\n",
      "        6.3238e-01, 3.9216e-01, 5.7741e-01, 5.6013e-01, 4.9385e-01, 6.6468e-01,\n",
      "        4.1337e-01, 5.5260e-01, 3.6400e-01, 2.3923e-01, 3.1633e-01, 2.9504e-04])\n",
      "tensor([7.6791e-01, 9.6564e-01, 7.8690e-01, 8.3817e-01, 3.6045e-01, 7.9651e-01,\n",
      "        2.3306e-01, 2.4834e-01, 7.5621e-01, 5.5005e-01, 5.5916e-01, 4.1748e-01,\n",
      "        6.8883e-01, 3.2043e-01, 4.4863e-01, 2.9871e-01, 5.0277e-01, 8.9213e-01,\n",
      "        8.7390e-01, 5.1962e-01, 5.8366e-01, 5.3916e-01, 4.9375e-01, 6.0633e-01,\n",
      "        2.7064e-01, 4.4210e-01, 3.0015e-01, 2.4772e-01, 3.1961e-01, 3.8924e-05])\n",
      "tensor([2.3532e-01, 8.8275e-01, 7.6710e-01, 8.2263e-01, 5.5980e-01, 8.0119e-01,\n",
      "        2.1982e-01, 2.4957e-01, 7.8906e-01, 3.9807e-01, 5.1744e-01, 6.2603e-01,\n",
      "        5.1454e-01, 3.6044e-01, 2.8335e-01, 3.5095e-01, 4.1424e-01, 7.4962e-01,\n",
      "        7.2166e-01, 5.0953e-01, 5.7912e-01, 5.6548e-01, 5.0772e-01, 6.6208e-01,\n",
      "        3.2817e-01, 6.2596e-01, 5.3347e-01, 2.5026e-01, 3.3285e-01, 3.8924e-05])\n",
      "tensor([8.5072e-01, 9.2322e-01, 7.9501e-01, 9.0600e-01, 2.8274e-01, 7.6853e-01,\n",
      "        2.7702e-01, 2.5501e-01, 7.1745e-01, 6.3443e-01, 5.9500e-01, 1.9048e-01,\n",
      "        6.9142e-01, 3.7262e-01, 5.2202e-01, 2.1887e-01, 4.6611e-01, 7.9932e-01,\n",
      "        7.6961e-01, 5.0583e-01, 5.6510e-01, 6.6168e-01, 4.5046e-01, 6.7226e-01,\n",
      "        2.4052e-01, 5.8965e-01, 3.7320e-01, 2.3877e-01, 3.1211e-01, 3.1139e-04])\n",
      "tensor([2.8291e-01, 9.2195e-01, 7.8197e-01, 9.0860e-01, 2.9845e-01, 7.5789e-01,\n",
      "        2.5530e-01, 2.5319e-01, 7.9155e-01, 5.2036e-01, 5.5462e-01, 4.3726e-01,\n",
      "        5.7113e-01, 3.6967e-01, 5.2988e-01, 3.2670e-01, 3.7087e-01, 5.2366e-01,\n",
      "        5.6586e-01, 5.6318e-01, 5.8054e-01, 5.7271e-01, 5.4455e-01, 6.6313e-01,\n",
      "        3.7541e-01, 5.9297e-01, 3.4877e-01, 2.2862e-01, 3.1004e-01, 7.6797e-04])\n",
      "tensor([0.3109, 0.9303, 0.7806, 0.9002, 0.3511, 0.7487, 0.2541, 0.2510, 0.7946,\n",
      "        0.5077, 0.5494, 0.3551, 0.5390, 0.3534, 0.5467, 0.4812, 0.3443, 0.5688,\n",
      "        0.5402, 0.7288, 0.5812, 0.5724, 0.5442, 0.6704, 0.4351, 0.5625, 0.5565,\n",
      "        0.2478, 0.3154, 0.0044])\n",
      "tensor([0.4397, 0.8710, 0.8049, 0.8080, 0.4365, 0.7382, 0.2430, 0.2320, 0.8114,\n",
      "        0.4390, 0.4594, 0.5056, 0.4303, 0.4738, 0.3616, 0.4330, 0.2593, 0.4238,\n",
      "        0.4108, 0.6990, 0.5837, 0.5797, 0.5155, 0.6605, 0.4011, 0.5961, 0.3959,\n",
      "        0.2427, 0.3265, 0.0039])\n",
      "tensor([5.8046e-01, 5.7873e-01, 9.3119e-01, 4.8484e-01, 5.6416e-01, 6.7024e-01,\n",
      "        2.5836e-01, 9.3466e-02, 6.2869e-01, 1.6188e-01, 9.1356e-02, 5.6713e-01,\n",
      "        2.5474e-01, 3.3211e-01, 5.1705e-01, 1.2593e-01, 1.6695e-01, 2.7131e-01,\n",
      "        1.8902e-01, 5.5323e-01, 6.2392e-01, 4.1462e-01, 7.0404e-01, 6.8642e-01,\n",
      "        4.3382e-01, 6.0301e-01, 3.2208e-01, 1.3287e-01, 3.0363e-01, 3.8924e-05])\n",
      "tensor([2.0074e-01, 9.4367e-01, 8.0030e-01, 8.2403e-01, 4.9224e-01, 7.4893e-01,\n",
      "        2.4481e-01, 2.3198e-01, 7.9814e-01, 3.9691e-01, 4.4001e-01, 5.6656e-01,\n",
      "        3.7896e-01, 5.3958e-01, 2.7007e-01, 3.6450e-01, 2.4159e-01, 3.4209e-01,\n",
      "        3.4514e-01, 5.9705e-01, 5.9183e-01, 5.8071e-01, 5.1425e-01, 6.6036e-01,\n",
      "        3.5314e-01, 6.3702e-01, 4.6974e-01, 2.7148e-01, 3.2715e-01, 7.4033e-04])\n",
      "tensor([0.1659, 0.4737, 0.9348, 0.3591, 0.5377, 0.6258, 0.2141, 0.1466, 0.9865,\n",
      "        0.4081, 0.4180, 0.5341, 0.4843, 0.5425, 0.4668, 0.3220, 0.2786, 0.3990,\n",
      "        0.3303, 0.6174, 0.5984, 0.5906, 0.4112, 0.6459, 0.4051, 0.6931, 0.3911,\n",
      "        0.2698, 0.3208, 0.0039])\n",
      "tensor([7.5085e-01, 9.3457e-01, 7.9489e-01, 8.0530e-01, 4.0941e-01, 7.7265e-01,\n",
      "        2.3336e-01, 2.5604e-01, 7.8742e-01, 5.0127e-01, 4.7746e-01, 4.8019e-01,\n",
      "        4.8194e-01, 3.4947e-01, 2.6874e-01, 3.5551e-01, 3.6993e-01, 6.8498e-01,\n",
      "        6.6157e-01, 5.7660e-01, 5.8060e-01, 5.6379e-01, 4.9183e-01, 6.7072e-01,\n",
      "        2.7951e-01, 5.8332e-01, 3.4576e-01, 2.3991e-01, 3.0824e-01, 3.8924e-05])\n",
      "tensor([5.2968e-01, 9.9150e-01, 7.8446e-01, 8.3766e-01, 3.5736e-01, 7.7994e-01,\n",
      "        2.4710e-01, 2.6934e-01, 7.8332e-01, 6.1307e-01, 5.4625e-01, 4.9369e-01,\n",
      "        5.5651e-01, 3.6970e-01, 4.8787e-01, 2.5795e-01, 5.0834e-01, 9.0617e-01,\n",
      "        8.9616e-01, 4.6990e-01, 5.7781e-01, 5.5383e-01, 4.6456e-01, 6.6472e-01,\n",
      "        3.7906e-01, 5.9824e-01, 3.3222e-01, 2.3901e-01, 3.1479e-01, 3.8924e-05])\n",
      "tensor([0.2381, 0.8680, 0.8110, 0.7578, 0.6218, 0.7272, 0.2324, 0.1984, 0.8219,\n",
      "        0.3016, 0.3302, 0.7417, 0.1654, 0.4891, 0.1267, 0.4057, 0.0553, 0.0762,\n",
      "        0.1040, 0.7970, 0.5925, 0.5991, 0.5503, 0.6563, 0.4528, 0.5379, 0.4785,\n",
      "        0.2925, 0.3232, 0.0034])\n",
      "tensor([5.4380e-01, 7.6466e-01, 8.4918e-01, 5.6658e-01, 5.4946e-01, 6.9722e-01,\n",
      "        2.1882e-01, 1.6853e-01, 8.0773e-01, 3.5134e-01, 2.3202e-01, 7.0709e-01,\n",
      "        1.3960e-01, 4.3685e-01, 3.1198e-01, 2.4337e-01, 7.8964e-02, 1.9697e-01,\n",
      "        1.4416e-01, 7.1494e-01, 5.8249e-01, 5.6694e-01, 5.7268e-01, 6.6899e-01,\n",
      "        4.5428e-01, 5.6809e-01, 3.4374e-01, 1.9691e-01, 3.0147e-01, 4.4373e-04])\n",
      "tensor([0.2416, 0.9219, 0.7786, 0.8674, 0.3133, 0.7387, 0.2705, 0.2746, 0.7875,\n",
      "        0.4592, 0.5129, 0.5442, 0.5959, 0.4846, 0.4929, 0.3837, 0.3571, 0.5953,\n",
      "        0.5010, 0.6645, 0.5874, 0.5638, 0.4687, 0.6747, 0.3952, 0.5673, 0.5125,\n",
      "        0.2486, 0.3089, 0.0312])\n",
      "tensor([4.6819e-02, 9.2800e-01, 8.0316e-01, 8.4746e-01, 3.6831e-01, 7.5241e-01,\n",
      "        2.3556e-01, 2.4446e-01, 8.0054e-01, 5.2896e-01, 4.6163e-01, 5.4496e-01,\n",
      "        3.9350e-01, 4.7510e-01, 4.2446e-01, 3.5096e-01, 3.5304e-01, 6.0867e-01,\n",
      "        5.6982e-01, 5.4259e-01, 5.8414e-01, 5.6880e-01, 4.8309e-01, 6.6612e-01,\n",
      "        4.4445e-01, 5.8038e-01, 4.7538e-01, 2.5119e-01, 3.1807e-01, 3.8924e-05])\n",
      "tensor([8.5683e-01, 9.7972e-01, 7.9603e-01, 8.1675e-01, 4.8877e-01, 7.7546e-01,\n",
      "        2.4852e-01, 2.5988e-01, 7.8671e-01, 4.4582e-01, 5.3687e-01, 4.0370e-01,\n",
      "        5.5394e-01, 4.9301e-01, 3.6073e-01, 2.7105e-01, 4.2817e-01, 6.9125e-01,\n",
      "        6.4612e-01, 4.4876e-01, 5.8360e-01, 5.6485e-01, 4.9016e-01, 6.6314e-01,\n",
      "        3.7970e-01, 6.1340e-01, 4.5696e-01, 2.4968e-01, 3.1882e-01, 6.1889e-05])\n",
      "tensor([7.4422e-01, 8.6802e-01, 7.9537e-01, 8.3931e-01, 2.6943e-01, 7.6308e-01,\n",
      "        2.6989e-01, 2.3408e-01, 7.0056e-01, 5.7081e-01, 5.5959e-01, 4.0193e-01,\n",
      "        6.3091e-01, 3.9472e-01, 4.9991e-01, 2.0080e-01, 3.9146e-01, 6.2227e-01,\n",
      "        5.9274e-01, 5.8424e-01, 5.5212e-01, 7.0116e-01, 3.8331e-01, 6.7261e-01,\n",
      "        3.9291e-01, 5.9537e-01, 5.1620e-01, 2.4265e-01, 3.2049e-01, 3.8924e-05])\n",
      "tensor([2.1510e-01, 8.2368e-01, 7.1241e-01, 8.6312e-01, 4.4789e-01, 7.8101e-01,\n",
      "        2.2889e-01, 2.3317e-01, 7.8680e-01, 5.8948e-01, 5.9731e-01, 4.7950e-01,\n",
      "        6.0171e-01, 4.3872e-01, 4.6869e-01, 3.7907e-01, 3.5408e-01, 5.9461e-01,\n",
      "        5.3556e-01, 7.9956e-01, 5.5716e-01, 5.4964e-01, 4.8204e-01, 5.9254e-01,\n",
      "        4.3750e-01, 5.1236e-01, 5.1047e-01, 2.8507e-01, 2.8162e-01, 4.7915e-04])\n",
      "tensor([9.6580e-01, 9.9383e-01, 7.5927e-01, 8.9755e-01, 2.1844e-01, 7.6154e-01,\n",
      "        2.5978e-01, 2.5876e-01, 7.8664e-01, 5.5578e-01, 6.2353e-01, 3.6487e-01,\n",
      "        6.9176e-01, 4.2019e-01, 5.8470e-01, 3.1363e-01, 5.0794e-01, 7.6583e-01,\n",
      "        6.5587e-01, 5.9636e-01, 5.8066e-01, 5.6613e-01, 5.4884e-01, 6.6754e-01,\n",
      "        4.6209e-01, 5.6690e-01, 4.0312e-01, 2.3888e-01, 3.1281e-01, 7.7653e-04])\n",
      "tensor([0.5435, 0.7660, 0.8431, 0.6693, 0.6553, 0.6978, 0.2385, 0.1789, 0.8331,\n",
      "        0.2985, 0.3005, 0.6455, 0.1118, 0.4575, 0.3551, 0.1423, 0.0922, 0.1040,\n",
      "        0.0281, 0.6548, 0.5783, 0.5789, 0.4937, 0.6726, 0.4713, 0.5556, 0.3579,\n",
      "        0.2144, 0.3084, 0.0015])\n",
      "tensor([2.5692e-01, 8.7985e-01, 8.0591e-01, 8.1937e-01, 4.2397e-01, 7.4375e-01,\n",
      "        2.5378e-01, 2.3054e-01, 7.9430e-01, 4.5811e-01, 4.7350e-01, 4.9495e-01,\n",
      "        4.5962e-01, 3.6993e-01, 4.0893e-01, 3.9006e-01, 2.3393e-01, 4.8159e-01,\n",
      "        3.4305e-01, 6.5295e-01, 5.7658e-01, 6.0498e-01, 5.0877e-01, 6.7088e-01,\n",
      "        3.6566e-01, 5.6104e-01, 3.8625e-01, 2.3398e-01, 3.1164e-01, 3.8924e-05])\n",
      "tensor([0.7510, 0.9169, 0.8013, 0.7946, 0.4112, 0.7584, 0.2455, 0.2651, 0.7886,\n",
      "        0.4867, 0.4707, 0.4785, 0.4795, 0.3589, 0.2761, 0.3753, 0.3741, 0.6918,\n",
      "        0.6663, 0.6042, 0.5773, 0.5609, 0.4905, 0.6678, 0.2859, 0.6042, 0.3685,\n",
      "        0.2485, 0.3065, 0.0141])\n",
      "tensor([0.2368, 0.9117, 0.8059, 0.8420, 0.4887, 0.7478, 0.2621, 0.2386, 0.7824,\n",
      "        0.4427, 0.5051, 0.5214, 0.4273, 0.3583, 0.3695, 0.3931, 0.2340, 0.4750,\n",
      "        0.3391, 0.6513, 0.5822, 0.6005, 0.5055, 0.6711, 0.3614, 0.5552, 0.4708,\n",
      "        0.2584, 0.3176, 0.0044])\n",
      "tensor([0.3679, 0.9474, 0.7664, 0.9444, 0.3140, 0.7640, 0.2732, 0.2733, 0.7839,\n",
      "        0.5435, 0.6150, 0.2305, 0.6811, 0.4637, 0.6466, 0.4972, 0.4326, 0.7295,\n",
      "        0.6841, 0.6542, 0.5894, 0.5670, 0.5455, 0.6707, 0.2773, 0.5739, 0.4200,\n",
      "        0.2369, 0.3119, 0.0113])\n",
      "tensor([0.1081, 0.7487, 0.8146, 0.6044, 0.7000, 0.6956, 0.2643, 0.1703, 0.7730,\n",
      "        0.3380, 0.2924, 0.8089, 0.1933, 0.5385, 0.3162, 0.3588, 0.1471, 0.2214,\n",
      "        0.1861, 0.7249, 0.5794, 0.5278, 0.5914, 0.6859, 0.3075, 0.4875, 0.4506,\n",
      "        0.2676, 0.2752, 0.0073])\n",
      "tensor([6.4123e-02, 9.2218e-01, 8.3029e-01, 7.1012e-01, 6.5121e-01, 7.5434e-01,\n",
      "        2.3432e-01, 2.1777e-01, 8.0717e-01, 3.1280e-01, 2.9491e-01, 1.0000e+00,\n",
      "        3.4470e-02, 4.1497e-01, 0.0000e+00, 2.5841e-01, 1.2286e-01, 2.8066e-01,\n",
      "        2.7537e-01, 5.3126e-01, 5.9617e-01, 5.8802e-01, 4.9704e-01, 6.5556e-01,\n",
      "        2.2531e-01, 6.7343e-01, 5.3829e-01, 2.8947e-01, 3.3563e-01, 3.8924e-05])\n",
      "tensor([6.7335e-02, 9.7391e-01, 8.1157e-01, 7.7675e-01, 5.8116e-01, 7.7324e-01,\n",
      "        2.3400e-01, 2.5719e-01, 7.8929e-01, 4.6881e-01, 5.1339e-01, 5.5705e-01,\n",
      "        4.1665e-01, 5.8255e-01, 3.2863e-01, 3.2918e-01, 4.1011e-01, 7.7855e-01,\n",
      "        7.4378e-01, 5.4089e-01, 5.8597e-01, 5.6658e-01, 5.1261e-01, 6.6856e-01,\n",
      "        3.2592e-01, 5.2676e-01, 5.0165e-01, 2.5351e-01, 3.1633e-01, 3.8924e-05])\n",
      "tensor([6.3711e-01, 9.9117e-01, 7.7412e-01, 9.1479e-01, 4.2871e-01, 7.6784e-01,\n",
      "        2.6202e-01, 2.6522e-01, 7.8354e-01, 5.8318e-01, 6.4420e-01, 2.5986e-01,\n",
      "        5.9950e-01, 5.7506e-01, 6.9888e-01, 2.2202e-01, 4.7825e-01, 7.2758e-01,\n",
      "        6.4613e-01, 4.3181e-01, 5.7660e-01, 5.5868e-01, 5.0112e-01, 6.6870e-01,\n",
      "        3.5305e-01, 5.7023e-01, 4.0422e-01, 2.3719e-01, 3.1209e-01, 3.8924e-05])\n",
      "tensor([0.5931, 0.9255, 0.8102, 0.8276, 0.5134, 0.7620, 0.2474, 0.2420, 0.7927,\n",
      "        0.4157, 0.4495, 0.7028, 0.2857, 0.5808, 0.2948, 0.1200, 0.2502, 0.3927,\n",
      "        0.4159, 0.5237, 0.5903, 0.5798, 0.5415, 0.6575, 0.3238, 0.5992, 0.4578,\n",
      "        0.2593, 0.3178, 0.0000])\n",
      "tensor([0.9068, 0.9561, 0.7688, 0.9032, 0.2316, 0.7712, 0.2579, 0.2737, 0.7831,\n",
      "        0.5705, 0.5768, 0.2377, 0.7231, 0.5349, 0.5850, 0.2796, 0.4527, 0.7520,\n",
      "        0.6674, 0.5593, 0.5845, 0.5610, 0.4985, 0.6726, 0.4307, 0.5534, 0.3849,\n",
      "        0.2389, 0.3153, 0.0073])\n",
      "tensor([2.0044e-01, 9.6396e-01, 7.8519e-01, 8.7081e-01, 4.1346e-01, 7.6178e-01,\n",
      "        2.5644e-01, 2.5149e-01, 7.9263e-01, 4.7559e-01, 5.4610e-01, 4.5191e-01,\n",
      "        5.3863e-01, 3.4231e-01, 4.6693e-01, 3.4324e-01, 4.0612e-01, 5.8308e-01,\n",
      "        6.3004e-01, 5.5362e-01, 5.8377e-01, 5.6904e-01, 5.0330e-01, 6.6071e-01,\n",
      "        2.7852e-01, 6.2325e-01, 4.6272e-01, 2.5167e-01, 3.1932e-01, 7.3800e-04])\n",
      "tensor([2.4877e-01, 8.8905e-01, 7.7742e-01, 8.2359e-01, 4.7162e-01, 7.6463e-01,\n",
      "        2.3454e-01, 2.1894e-01, 8.0275e-01, 4.3554e-01, 4.3797e-01, 6.5865e-01,\n",
      "        3.4964e-01, 3.0754e-01, 2.8495e-01, 3.4784e-01, 1.8136e-01, 3.3881e-01,\n",
      "        3.2915e-01, 7.6873e-01, 5.8089e-01, 5.7810e-01, 5.1774e-01, 6.5032e-01,\n",
      "        3.1783e-01, 5.6079e-01, 4.0812e-01, 2.8416e-01, 3.2350e-01, 3.8924e-05])\n",
      "tensor([5.4610e-01, 5.0881e-01, 9.4133e-01, 3.4559e-01, 6.4664e-01, 6.4526e-01,\n",
      "        2.5067e-01, 7.5298e-02, 6.6268e-01, 1.6268e-01, 6.0280e-02, 5.4812e-01,\n",
      "        3.0497e-01, 3.9385e-01, 5.1404e-01, 1.5005e-01, 2.3279e-01, 3.6902e-01,\n",
      "        2.7495e-01, 5.1896e-01, 6.1021e-01, 4.2033e-01, 6.7148e-01, 6.7875e-01,\n",
      "        4.1657e-01, 5.3648e-01, 2.6756e-01, 6.3405e-02, 2.8624e-01, 3.8924e-05])\n",
      "tensor([0.2633, 0.9753, 0.7678, 0.9136, 0.3182, 0.7670, 0.2649, 0.2653, 0.7870,\n",
      "        0.5862, 0.5974, 0.2268, 0.6828, 0.3628, 0.5996, 0.3615, 0.4583, 0.7640,\n",
      "        0.6597, 0.5400, 0.5804, 0.5561, 0.4627, 0.6635, 0.2547, 0.6035, 0.3514,\n",
      "        0.2395, 0.3144, 0.0041])\n",
      "tensor([0.8274, 0.9661, 0.7818, 0.9109, 0.3763, 0.7777, 0.2640, 0.2732, 0.7839,\n",
      "        0.4902, 0.6412, 0.1841, 0.6951, 0.4837, 0.6507, 0.1884, 0.4612, 0.7079,\n",
      "        0.6054, 0.4464, 0.5774, 0.5632, 0.5273, 0.6662, 0.4363, 0.5372, 0.3923,\n",
      "        0.2406, 0.3151, 0.0000])\n",
      "tensor([5.8481e-01, 9.3340e-01, 7.5572e-01, 9.1911e-01, 2.9913e-01, 8.4041e-01,\n",
      "        2.0842e-01, 2.0822e-01, 7.8060e-01, 6.4573e-01, 6.6210e-01, 3.6667e-01,\n",
      "        6.4872e-01, 3.9223e-01, 7.6180e-01, 2.5879e-01, 3.9764e-01, 7.7234e-01,\n",
      "        5.5577e-01, 4.3433e-01, 5.6475e-01, 5.8019e-01, 4.5127e-01, 4.2809e-01,\n",
      "        2.6316e-01, 3.7938e-01, 3.2859e-01, 2.5467e-01, 3.2175e-01, 3.5810e-05])\n",
      "tensor([0.6325, 0.9413, 0.8026, 0.8149, 0.5550, 0.7637, 0.2640, 0.2505, 0.7992,\n",
      "        0.4451, 0.5054, 0.5646, 0.3739, 0.5246, 0.3999, 0.2508, 0.3421, 0.6076,\n",
      "        0.6237, 0.7042, 0.5929, 0.5686, 0.4777, 0.6699, 0.2936, 0.5836, 0.4958,\n",
      "        0.2583, 0.3198, 0.0072])\n",
      "tensor([0.4055, 0.9508, 0.7793, 0.8588, 0.3957, 0.7520, 0.2467, 0.2469, 0.7936,\n",
      "        0.4857, 0.4990, 0.5626, 0.5093, 0.3226, 0.4203, 0.3768, 0.3452, 0.5329,\n",
      "        0.5601, 0.5861, 0.5898, 0.5738, 0.4972, 0.6603, 0.4136, 0.6119, 0.3739,\n",
      "        0.2569, 0.3225, 0.0088])\n",
      "tensor([5.2477e-01, 9.1743e-01, 8.0670e-01, 8.7611e-01, 3.1255e-01, 7.6837e-01,\n",
      "        2.8232e-01, 2.4643e-01, 6.6992e-01, 7.0314e-01, 6.2656e-01, 3.0801e-01,\n",
      "        6.1890e-01, 5.4204e-01, 5.8282e-01, 2.6054e-01, 4.5684e-01, 8.2764e-01,\n",
      "        7.8440e-01, 5.1792e-01, 5.5747e-01, 7.2278e-01, 3.9551e-01, 6.9046e-01,\n",
      "        3.9817e-01, 4.9195e-01, 3.1187e-01, 2.3472e-01, 3.1031e-01, 2.7208e-04])\n",
      "tensor([2.7678e-01, 9.4322e-01, 7.8192e-01, 9.4348e-01, 3.2558e-01, 7.7251e-01,\n",
      "        2.5564e-01, 2.7057e-01, 7.8539e-01, 5.0793e-01, 6.0639e-01, 2.9368e-01,\n",
      "        6.8684e-01, 4.1986e-01, 6.0677e-01, 3.4241e-01, 4.7741e-01, 7.4862e-01,\n",
      "        6.3238e-01, 3.9216e-01, 5.7741e-01, 5.6013e-01, 4.9385e-01, 6.6468e-01,\n",
      "        4.1337e-01, 5.5260e-01, 3.6400e-01, 2.3923e-01, 3.1633e-01, 2.9504e-04])\n",
      "tensor([7.6791e-01, 9.6564e-01, 7.8690e-01, 8.3817e-01, 3.6045e-01, 7.9651e-01,\n",
      "        2.3306e-01, 2.4834e-01, 7.5621e-01, 5.5005e-01, 5.5916e-01, 4.1748e-01,\n",
      "        6.8883e-01, 3.2043e-01, 4.4863e-01, 2.9871e-01, 5.0277e-01, 8.9213e-01,\n",
      "        8.7390e-01, 5.1962e-01, 5.8366e-01, 5.3916e-01, 4.9375e-01, 6.0633e-01,\n",
      "        2.7064e-01, 4.4210e-01, 3.0015e-01, 2.4772e-01, 3.1961e-01, 3.8924e-05])\n",
      "tensor([2.3532e-01, 8.8275e-01, 7.6710e-01, 8.2263e-01, 5.5980e-01, 8.0119e-01,\n",
      "        2.1982e-01, 2.4957e-01, 7.8906e-01, 3.9807e-01, 5.1744e-01, 6.2603e-01,\n",
      "        5.1454e-01, 3.6044e-01, 2.8335e-01, 3.5095e-01, 4.1424e-01, 7.4962e-01,\n",
      "        7.2166e-01, 5.0953e-01, 5.7912e-01, 5.6548e-01, 5.0772e-01, 6.6208e-01,\n",
      "        3.2817e-01, 6.2596e-01, 5.3347e-01, 2.5026e-01, 3.3285e-01, 3.8924e-05])\n",
      "tensor([8.5072e-01, 9.2322e-01, 7.9501e-01, 9.0600e-01, 2.8274e-01, 7.6853e-01,\n",
      "        2.7702e-01, 2.5501e-01, 7.1745e-01, 6.3443e-01, 5.9500e-01, 1.9048e-01,\n",
      "        6.9142e-01, 3.7262e-01, 5.2202e-01, 2.1887e-01, 4.6611e-01, 7.9932e-01,\n",
      "        7.6961e-01, 5.0583e-01, 5.6510e-01, 6.6168e-01, 4.5046e-01, 6.7226e-01,\n",
      "        2.4052e-01, 5.8965e-01, 3.7320e-01, 2.3877e-01, 3.1211e-01, 3.1139e-04])\n",
      "tensor([2.8291e-01, 9.2195e-01, 7.8197e-01, 9.0860e-01, 2.9845e-01, 7.5789e-01,\n",
      "        2.5530e-01, 2.5319e-01, 7.9155e-01, 5.2036e-01, 5.5462e-01, 4.3726e-01,\n",
      "        5.7113e-01, 3.6967e-01, 5.2988e-01, 3.2670e-01, 3.7087e-01, 5.2366e-01,\n",
      "        5.6586e-01, 5.6318e-01, 5.8054e-01, 5.7271e-01, 5.4455e-01, 6.6313e-01,\n",
      "        3.7541e-01, 5.9297e-01, 3.4877e-01, 2.2862e-01, 3.1004e-01, 7.6797e-04])\n",
      "tensor([0.3109, 0.9303, 0.7806, 0.9002, 0.3511, 0.7487, 0.2541, 0.2510, 0.7946,\n",
      "        0.5077, 0.5494, 0.3551, 0.5390, 0.3534, 0.5467, 0.4812, 0.3443, 0.5688,\n",
      "        0.5402, 0.7288, 0.5812, 0.5724, 0.5442, 0.6704, 0.4351, 0.5625, 0.5565,\n",
      "        0.2478, 0.3154, 0.0044])\n",
      "tensor([0.4397, 0.8710, 0.8049, 0.8080, 0.4365, 0.7382, 0.2430, 0.2320, 0.8114,\n",
      "        0.4390, 0.4594, 0.5056, 0.4303, 0.4738, 0.3616, 0.4330, 0.2593, 0.4238,\n",
      "        0.4108, 0.6990, 0.5837, 0.5797, 0.5155, 0.6605, 0.4011, 0.5961, 0.3959,\n",
      "        0.2427, 0.3265, 0.0039])\n",
      "tensor([5.8046e-01, 5.7873e-01, 9.3119e-01, 4.8484e-01, 5.6416e-01, 6.7024e-01,\n",
      "        2.5836e-01, 9.3466e-02, 6.2869e-01, 1.6188e-01, 9.1356e-02, 5.6713e-01,\n",
      "        2.5474e-01, 3.3211e-01, 5.1705e-01, 1.2593e-01, 1.6695e-01, 2.7131e-01,\n",
      "        1.8902e-01, 5.5323e-01, 6.2392e-01, 4.1462e-01, 7.0404e-01, 6.8642e-01,\n",
      "        4.3382e-01, 6.0301e-01, 3.2208e-01, 1.3287e-01, 3.0363e-01, 3.8924e-05])\n",
      "tensor([2.0074e-01, 9.4367e-01, 8.0030e-01, 8.2403e-01, 4.9224e-01, 7.4893e-01,\n",
      "        2.4481e-01, 2.3198e-01, 7.9814e-01, 3.9691e-01, 4.4001e-01, 5.6656e-01,\n",
      "        3.7896e-01, 5.3958e-01, 2.7007e-01, 3.6450e-01, 2.4159e-01, 3.4209e-01,\n",
      "        3.4514e-01, 5.9705e-01, 5.9183e-01, 5.8071e-01, 5.1425e-01, 6.6036e-01,\n",
      "        3.5314e-01, 6.3702e-01, 4.6974e-01, 2.7148e-01, 3.2715e-01, 7.4033e-04])\n",
      "tensor([0.1659, 0.4737, 0.9348, 0.3591, 0.5377, 0.6258, 0.2141, 0.1466, 0.9865,\n",
      "        0.4081, 0.4180, 0.5341, 0.4843, 0.5425, 0.4668, 0.3220, 0.2786, 0.3990,\n",
      "        0.3303, 0.6174, 0.5984, 0.5906, 0.4112, 0.6459, 0.4051, 0.6931, 0.3911,\n",
      "        0.2698, 0.3208, 0.0039])\n",
      "tensor([7.5085e-01, 9.3457e-01, 7.9489e-01, 8.0530e-01, 4.0941e-01, 7.7265e-01,\n",
      "        2.3336e-01, 2.5604e-01, 7.8742e-01, 5.0127e-01, 4.7746e-01, 4.8019e-01,\n",
      "        4.8194e-01, 3.4947e-01, 2.6874e-01, 3.5551e-01, 3.6993e-01, 6.8498e-01,\n",
      "        6.6157e-01, 5.7660e-01, 5.8060e-01, 5.6379e-01, 4.9183e-01, 6.7072e-01,\n",
      "        2.7951e-01, 5.8332e-01, 3.4576e-01, 2.3991e-01, 3.0824e-01, 3.8924e-05])\n",
      "tensor([5.2968e-01, 9.9150e-01, 7.8446e-01, 8.3766e-01, 3.5736e-01, 7.7994e-01,\n",
      "        2.4710e-01, 2.6934e-01, 7.8332e-01, 6.1307e-01, 5.4625e-01, 4.9369e-01,\n",
      "        5.5651e-01, 3.6970e-01, 4.8787e-01, 2.5795e-01, 5.0834e-01, 9.0617e-01,\n",
      "        8.9616e-01, 4.6990e-01, 5.7781e-01, 5.5383e-01, 4.6456e-01, 6.6472e-01,\n",
      "        3.7906e-01, 5.9824e-01, 3.3222e-01, 2.3901e-01, 3.1479e-01, 3.8924e-05])\n",
      "tensor([0.2381, 0.8680, 0.8110, 0.7578, 0.6218, 0.7272, 0.2324, 0.1984, 0.8219,\n",
      "        0.3016, 0.3302, 0.7417, 0.1654, 0.4891, 0.1267, 0.4057, 0.0553, 0.0762,\n",
      "        0.1040, 0.7970, 0.5925, 0.5991, 0.5503, 0.6563, 0.4528, 0.5379, 0.4785,\n",
      "        0.2925, 0.3232, 0.0034])\n",
      "tensor([5.4380e-01, 7.6466e-01, 8.4918e-01, 5.6658e-01, 5.4946e-01, 6.9722e-01,\n",
      "        2.1882e-01, 1.6853e-01, 8.0773e-01, 3.5134e-01, 2.3202e-01, 7.0709e-01,\n",
      "        1.3960e-01, 4.3685e-01, 3.1198e-01, 2.4337e-01, 7.8964e-02, 1.9697e-01,\n",
      "        1.4416e-01, 7.1494e-01, 5.8249e-01, 5.6694e-01, 5.7268e-01, 6.6899e-01,\n",
      "        4.5428e-01, 5.6809e-01, 3.4374e-01, 1.9691e-01, 3.0147e-01, 4.4373e-04])\n",
      "tensor([0.2416, 0.9219, 0.7786, 0.8674, 0.3133, 0.7387, 0.2705, 0.2746, 0.7875,\n",
      "        0.4592, 0.5129, 0.5442, 0.5959, 0.4846, 0.4929, 0.3837, 0.3571, 0.5953,\n",
      "        0.5010, 0.6645, 0.5874, 0.5638, 0.4687, 0.6747, 0.3952, 0.5673, 0.5125,\n",
      "        0.2486, 0.3089, 0.0312])\n",
      "tensor([4.6819e-02, 9.2800e-01, 8.0316e-01, 8.4746e-01, 3.6831e-01, 7.5241e-01,\n",
      "        2.3556e-01, 2.4446e-01, 8.0054e-01, 5.2896e-01, 4.6163e-01, 5.4496e-01,\n",
      "        3.9350e-01, 4.7510e-01, 4.2446e-01, 3.5096e-01, 3.5304e-01, 6.0867e-01,\n",
      "        5.6982e-01, 5.4259e-01, 5.8414e-01, 5.6880e-01, 4.8309e-01, 6.6612e-01,\n",
      "        4.4445e-01, 5.8038e-01, 4.7538e-01, 2.5119e-01, 3.1807e-01, 3.8924e-05])\n",
      "tensor([8.5683e-01, 9.7972e-01, 7.9603e-01, 8.1675e-01, 4.8877e-01, 7.7546e-01,\n",
      "        2.4852e-01, 2.5988e-01, 7.8671e-01, 4.4582e-01, 5.3687e-01, 4.0370e-01,\n",
      "        5.5394e-01, 4.9301e-01, 3.6073e-01, 2.7105e-01, 4.2817e-01, 6.9125e-01,\n",
      "        6.4612e-01, 4.4876e-01, 5.8360e-01, 5.6485e-01, 4.9016e-01, 6.6314e-01,\n",
      "        3.7970e-01, 6.1340e-01, 4.5696e-01, 2.4968e-01, 3.1882e-01, 6.1889e-05])\n",
      "tensor([7.4422e-01, 8.6802e-01, 7.9537e-01, 8.3931e-01, 2.6943e-01, 7.6308e-01,\n",
      "        2.6989e-01, 2.3408e-01, 7.0056e-01, 5.7081e-01, 5.5959e-01, 4.0193e-01,\n",
      "        6.3091e-01, 3.9472e-01, 4.9991e-01, 2.0080e-01, 3.9146e-01, 6.2227e-01,\n",
      "        5.9274e-01, 5.8424e-01, 5.5212e-01, 7.0116e-01, 3.8331e-01, 6.7261e-01,\n",
      "        3.9291e-01, 5.9537e-01, 5.1620e-01, 2.4265e-01, 3.2049e-01, 3.8924e-05])\n",
      "tensor([2.1510e-01, 8.2368e-01, 7.1241e-01, 8.6312e-01, 4.4789e-01, 7.8101e-01,\n",
      "        2.2889e-01, 2.3317e-01, 7.8680e-01, 5.8948e-01, 5.9731e-01, 4.7950e-01,\n",
      "        6.0171e-01, 4.3872e-01, 4.6869e-01, 3.7907e-01, 3.5408e-01, 5.9461e-01,\n",
      "        5.3556e-01, 7.9956e-01, 5.5716e-01, 5.4964e-01, 4.8204e-01, 5.9254e-01,\n",
      "        4.3750e-01, 5.1236e-01, 5.1047e-01, 2.8507e-01, 2.8162e-01, 4.7915e-04])\n",
      "tensor([9.6580e-01, 9.9383e-01, 7.5927e-01, 8.9755e-01, 2.1844e-01, 7.6154e-01,\n",
      "        2.5978e-01, 2.5876e-01, 7.8664e-01, 5.5578e-01, 6.2353e-01, 3.6487e-01,\n",
      "        6.9176e-01, 4.2019e-01, 5.8470e-01, 3.1363e-01, 5.0794e-01, 7.6583e-01,\n",
      "        6.5587e-01, 5.9636e-01, 5.8066e-01, 5.6613e-01, 5.4884e-01, 6.6754e-01,\n",
      "        4.6209e-01, 5.6690e-01, 4.0312e-01, 2.3888e-01, 3.1281e-01, 7.7653e-04])\n",
      "tensor([0.5435, 0.7660, 0.8431, 0.6693, 0.6553, 0.6978, 0.2385, 0.1789, 0.8331,\n",
      "        0.2985, 0.3005, 0.6455, 0.1118, 0.4575, 0.3551, 0.1423, 0.0922, 0.1040,\n",
      "        0.0281, 0.6548, 0.5783, 0.5789, 0.4937, 0.6726, 0.4713, 0.5556, 0.3579,\n",
      "        0.2144, 0.3084, 0.0015])\n",
      "tensor([2.5692e-01, 8.7985e-01, 8.0591e-01, 8.1937e-01, 4.2397e-01, 7.4375e-01,\n",
      "        2.5378e-01, 2.3054e-01, 7.9430e-01, 4.5811e-01, 4.7350e-01, 4.9495e-01,\n",
      "        4.5962e-01, 3.6993e-01, 4.0893e-01, 3.9006e-01, 2.3393e-01, 4.8159e-01,\n",
      "        3.4305e-01, 6.5295e-01, 5.7658e-01, 6.0498e-01, 5.0877e-01, 6.7088e-01,\n",
      "        3.6566e-01, 5.6104e-01, 3.8625e-01, 2.3398e-01, 3.1164e-01, 3.8924e-05])\n",
      "tensor([0.7510, 0.9169, 0.8013, 0.7946, 0.4112, 0.7584, 0.2455, 0.2651, 0.7886,\n",
      "        0.4867, 0.4707, 0.4785, 0.4795, 0.3589, 0.2761, 0.3753, 0.3741, 0.6918,\n",
      "        0.6663, 0.6042, 0.5773, 0.5609, 0.4905, 0.6678, 0.2859, 0.6042, 0.3685,\n",
      "        0.2485, 0.3065, 0.0141])\n",
      "tensor([0.2368, 0.9117, 0.8059, 0.8420, 0.4887, 0.7478, 0.2621, 0.2386, 0.7824,\n",
      "        0.4427, 0.5051, 0.5214, 0.4273, 0.3583, 0.3695, 0.3931, 0.2340, 0.4750,\n",
      "        0.3391, 0.6513, 0.5822, 0.6005, 0.5055, 0.6711, 0.3614, 0.5552, 0.4708,\n",
      "        0.2584, 0.3176, 0.0044])\n",
      "tensor([0.3679, 0.9474, 0.7664, 0.9444, 0.3140, 0.7640, 0.2732, 0.2733, 0.7839,\n",
      "        0.5435, 0.6150, 0.2305, 0.6811, 0.4637, 0.6466, 0.4972, 0.4326, 0.7295,\n",
      "        0.6841, 0.6542, 0.5894, 0.5670, 0.5455, 0.6707, 0.2773, 0.5739, 0.4200,\n",
      "        0.2369, 0.3119, 0.0113])\n",
      "tensor([0.1081, 0.7487, 0.8146, 0.6044, 0.7000, 0.6956, 0.2643, 0.1703, 0.7730,\n",
      "        0.3380, 0.2924, 0.8089, 0.1933, 0.5385, 0.3162, 0.3588, 0.1471, 0.2214,\n",
      "        0.1861, 0.7249, 0.5794, 0.5278, 0.5914, 0.6859, 0.3075, 0.4875, 0.4506,\n",
      "        0.2676, 0.2752, 0.0073])\n",
      "tensor([6.4123e-02, 9.2218e-01, 8.3029e-01, 7.1012e-01, 6.5121e-01, 7.5434e-01,\n",
      "        2.3432e-01, 2.1777e-01, 8.0717e-01, 3.1280e-01, 2.9491e-01, 1.0000e+00,\n",
      "        3.4470e-02, 4.1497e-01, 0.0000e+00, 2.5841e-01, 1.2286e-01, 2.8066e-01,\n",
      "        2.7537e-01, 5.3126e-01, 5.9617e-01, 5.8802e-01, 4.9704e-01, 6.5556e-01,\n",
      "        2.2531e-01, 6.7343e-01, 5.3829e-01, 2.8947e-01, 3.3563e-01, 3.8924e-05])\n",
      "tensor([6.7335e-02, 9.7391e-01, 8.1157e-01, 7.7675e-01, 5.8116e-01, 7.7324e-01,\n",
      "        2.3400e-01, 2.5719e-01, 7.8929e-01, 4.6881e-01, 5.1339e-01, 5.5705e-01,\n",
      "        4.1665e-01, 5.8255e-01, 3.2863e-01, 3.2918e-01, 4.1011e-01, 7.7855e-01,\n",
      "        7.4378e-01, 5.4089e-01, 5.8597e-01, 5.6658e-01, 5.1261e-01, 6.6856e-01,\n",
      "        3.2592e-01, 5.2676e-01, 5.0165e-01, 2.5351e-01, 3.1633e-01, 3.8924e-05])\n",
      "tensor([6.3711e-01, 9.9117e-01, 7.7412e-01, 9.1479e-01, 4.2871e-01, 7.6784e-01,\n",
      "        2.6202e-01, 2.6522e-01, 7.8354e-01, 5.8318e-01, 6.4420e-01, 2.5986e-01,\n",
      "        5.9950e-01, 5.7506e-01, 6.9888e-01, 2.2202e-01, 4.7825e-01, 7.2758e-01,\n",
      "        6.4613e-01, 4.3181e-01, 5.7660e-01, 5.5868e-01, 5.0112e-01, 6.6870e-01,\n",
      "        3.5305e-01, 5.7023e-01, 4.0422e-01, 2.3719e-01, 3.1209e-01, 3.8924e-05])\n",
      "tensor([0.5931, 0.9255, 0.8102, 0.8276, 0.5134, 0.7620, 0.2474, 0.2420, 0.7927,\n",
      "        0.4157, 0.4495, 0.7028, 0.2857, 0.5808, 0.2948, 0.1200, 0.2502, 0.3927,\n",
      "        0.4159, 0.5237, 0.5903, 0.5798, 0.5415, 0.6575, 0.3238, 0.5992, 0.4578,\n",
      "        0.2593, 0.3178, 0.0000])\n",
      "tensor([0.9068, 0.9561, 0.7688, 0.9032, 0.2316, 0.7712, 0.2579, 0.2737, 0.7831,\n",
      "        0.5705, 0.5768, 0.2377, 0.7231, 0.5349, 0.5850, 0.2796, 0.4527, 0.7520,\n",
      "        0.6674, 0.5593, 0.5845, 0.5610, 0.4985, 0.6726, 0.4307, 0.5534, 0.3849,\n",
      "        0.2389, 0.3153, 0.0073])\n",
      "tensor([2.0044e-01, 9.6396e-01, 7.8519e-01, 8.7081e-01, 4.1346e-01, 7.6178e-01,\n",
      "        2.5644e-01, 2.5149e-01, 7.9263e-01, 4.7559e-01, 5.4610e-01, 4.5191e-01,\n",
      "        5.3863e-01, 3.4231e-01, 4.6693e-01, 3.4324e-01, 4.0612e-01, 5.8308e-01,\n",
      "        6.3004e-01, 5.5362e-01, 5.8377e-01, 5.6904e-01, 5.0330e-01, 6.6071e-01,\n",
      "        2.7852e-01, 6.2325e-01, 4.6272e-01, 2.5167e-01, 3.1932e-01, 7.3800e-04])\n",
      "tensor([2.4877e-01, 8.8905e-01, 7.7742e-01, 8.2359e-01, 4.7162e-01, 7.6463e-01,\n",
      "        2.3454e-01, 2.1894e-01, 8.0275e-01, 4.3554e-01, 4.3797e-01, 6.5865e-01,\n",
      "        3.4964e-01, 3.0754e-01, 2.8495e-01, 3.4784e-01, 1.8136e-01, 3.3881e-01,\n",
      "        3.2915e-01, 7.6873e-01, 5.8089e-01, 5.7810e-01, 5.1774e-01, 6.5032e-01,\n",
      "        3.1783e-01, 5.6079e-01, 4.0812e-01, 2.8416e-01, 3.2350e-01, 3.8924e-05])\n",
      "tensor([5.4610e-01, 5.0881e-01, 9.4133e-01, 3.4559e-01, 6.4664e-01, 6.4526e-01,\n",
      "        2.5067e-01, 7.5298e-02, 6.6268e-01, 1.6268e-01, 6.0280e-02, 5.4812e-01,\n",
      "        3.0497e-01, 3.9385e-01, 5.1404e-01, 1.5005e-01, 2.3279e-01, 3.6902e-01,\n",
      "        2.7495e-01, 5.1896e-01, 6.1021e-01, 4.2033e-01, 6.7148e-01, 6.7875e-01,\n",
      "        4.1657e-01, 5.3648e-01, 2.6756e-01, 6.3405e-02, 2.8624e-01, 3.8924e-05])\n",
      "tensor([0.2633, 0.9753, 0.7678, 0.9136, 0.3182, 0.7670, 0.2649, 0.2653, 0.7870,\n",
      "        0.5862, 0.5974, 0.2268, 0.6828, 0.3628, 0.5996, 0.3615, 0.4583, 0.7640,\n",
      "        0.6597, 0.5400, 0.5804, 0.5561, 0.4627, 0.6635, 0.2547, 0.6035, 0.3514,\n",
      "        0.2395, 0.3144, 0.0041])\n",
      "tensor([0.8274, 0.9661, 0.7818, 0.9109, 0.3763, 0.7777, 0.2640, 0.2732, 0.7839,\n",
      "        0.4902, 0.6412, 0.1841, 0.6951, 0.4837, 0.6507, 0.1884, 0.4612, 0.7079,\n",
      "        0.6054, 0.4464, 0.5774, 0.5632, 0.5273, 0.6662, 0.4363, 0.5372, 0.3923,\n",
      "        0.2406, 0.3151, 0.0000])\n",
      "tensor([5.8481e-01, 9.3340e-01, 7.5572e-01, 9.1911e-01, 2.9913e-01, 8.4041e-01,\n",
      "        2.0842e-01, 2.0822e-01, 7.8060e-01, 6.4573e-01, 6.6210e-01, 3.6667e-01,\n",
      "        6.4872e-01, 3.9223e-01, 7.6180e-01, 2.5879e-01, 3.9764e-01, 7.7234e-01,\n",
      "        5.5577e-01, 4.3433e-01, 5.6475e-01, 5.8019e-01, 4.5127e-01, 4.2809e-01,\n",
      "        2.6316e-01, 3.7938e-01, 3.2859e-01, 2.5467e-01, 3.2175e-01, 3.5810e-05])\n",
      "tensor([0.6325, 0.9413, 0.8026, 0.8149, 0.5550, 0.7637, 0.2640, 0.2505, 0.7992,\n",
      "        0.4451, 0.5054, 0.5646, 0.3739, 0.5246, 0.3999, 0.2508, 0.3421, 0.6076,\n",
      "        0.6237, 0.7042, 0.5929, 0.5686, 0.4777, 0.6699, 0.2936, 0.5836, 0.4958,\n",
      "        0.2583, 0.3198, 0.0072])\n",
      "tensor([0.4055, 0.9508, 0.7793, 0.8588, 0.3957, 0.7520, 0.2467, 0.2469, 0.7936,\n",
      "        0.4857, 0.4990, 0.5626, 0.5093, 0.3226, 0.4203, 0.3768, 0.3452, 0.5329,\n",
      "        0.5601, 0.5861, 0.5898, 0.5738, 0.4972, 0.6603, 0.4136, 0.6119, 0.3739,\n",
      "        0.2569, 0.3225, 0.0088])\n",
      "tensor([5.2477e-01, 9.1743e-01, 8.0670e-01, 8.7611e-01, 3.1255e-01, 7.6837e-01,\n",
      "        2.8232e-01, 2.4643e-01, 6.6992e-01, 7.0314e-01, 6.2656e-01, 3.0801e-01,\n",
      "        6.1890e-01, 5.4204e-01, 5.8282e-01, 2.6054e-01, 4.5684e-01, 8.2764e-01,\n",
      "        7.8440e-01, 5.1792e-01, 5.5747e-01, 7.2278e-01, 3.9551e-01, 6.9046e-01,\n",
      "        3.9817e-01, 4.9195e-01, 3.1187e-01, 2.3472e-01, 3.1031e-01, 2.7208e-04])\n",
      "tensor([2.7678e-01, 9.4322e-01, 7.8192e-01, 9.4348e-01, 3.2558e-01, 7.7251e-01,\n",
      "        2.5564e-01, 2.7057e-01, 7.8539e-01, 5.0793e-01, 6.0639e-01, 2.9368e-01,\n",
      "        6.8684e-01, 4.1986e-01, 6.0677e-01, 3.4241e-01, 4.7741e-01, 7.4862e-01,\n",
      "        6.3238e-01, 3.9216e-01, 5.7741e-01, 5.6013e-01, 4.9385e-01, 6.6468e-01,\n",
      "        4.1337e-01, 5.5260e-01, 3.6400e-01, 2.3923e-01, 3.1633e-01, 2.9504e-04])\n",
      "tensor([7.6791e-01, 9.6564e-01, 7.8690e-01, 8.3817e-01, 3.6045e-01, 7.9651e-01,\n",
      "        2.3306e-01, 2.4834e-01, 7.5621e-01, 5.5005e-01, 5.5916e-01, 4.1748e-01,\n",
      "        6.8883e-01, 3.2043e-01, 4.4863e-01, 2.9871e-01, 5.0277e-01, 8.9213e-01,\n",
      "        8.7390e-01, 5.1962e-01, 5.8366e-01, 5.3916e-01, 4.9375e-01, 6.0633e-01,\n",
      "        2.7064e-01, 4.4210e-01, 3.0015e-01, 2.4772e-01, 3.1961e-01, 3.8924e-05])\n",
      "tensor([2.3532e-01, 8.8275e-01, 7.6710e-01, 8.2263e-01, 5.5980e-01, 8.0119e-01,\n",
      "        2.1982e-01, 2.4957e-01, 7.8906e-01, 3.9807e-01, 5.1744e-01, 6.2603e-01,\n",
      "        5.1454e-01, 3.6044e-01, 2.8335e-01, 3.5095e-01, 4.1424e-01, 7.4962e-01,\n",
      "        7.2166e-01, 5.0953e-01, 5.7912e-01, 5.6548e-01, 5.0772e-01, 6.6208e-01,\n",
      "        3.2817e-01, 6.2596e-01, 5.3347e-01, 2.5026e-01, 3.3285e-01, 3.8924e-05])\n",
      "tensor([8.5072e-01, 9.2322e-01, 7.9501e-01, 9.0600e-01, 2.8274e-01, 7.6853e-01,\n",
      "        2.7702e-01, 2.5501e-01, 7.1745e-01, 6.3443e-01, 5.9500e-01, 1.9048e-01,\n",
      "        6.9142e-01, 3.7262e-01, 5.2202e-01, 2.1887e-01, 4.6611e-01, 7.9932e-01,\n",
      "        7.6961e-01, 5.0583e-01, 5.6510e-01, 6.6168e-01, 4.5046e-01, 6.7226e-01,\n",
      "        2.4052e-01, 5.8965e-01, 3.7320e-01, 2.3877e-01, 3.1211e-01, 3.1139e-04])\n",
      "tensor([2.8291e-01, 9.2195e-01, 7.8197e-01, 9.0860e-01, 2.9845e-01, 7.5789e-01,\n",
      "        2.5530e-01, 2.5319e-01, 7.9155e-01, 5.2036e-01, 5.5462e-01, 4.3726e-01,\n",
      "        5.7113e-01, 3.6967e-01, 5.2988e-01, 3.2670e-01, 3.7087e-01, 5.2366e-01,\n",
      "        5.6586e-01, 5.6318e-01, 5.8054e-01, 5.7271e-01, 5.4455e-01, 6.6313e-01,\n",
      "        3.7541e-01, 5.9297e-01, 3.4877e-01, 2.2862e-01, 3.1004e-01, 7.6797e-04])\n",
      "tensor([0.3109, 0.9303, 0.7806, 0.9002, 0.3511, 0.7487, 0.2541, 0.2510, 0.7946,\n",
      "        0.5077, 0.5494, 0.3551, 0.5390, 0.3534, 0.5467, 0.4812, 0.3443, 0.5688,\n",
      "        0.5402, 0.7288, 0.5812, 0.5724, 0.5442, 0.6704, 0.4351, 0.5625, 0.5565,\n",
      "        0.2478, 0.3154, 0.0044])\n",
      "tensor([0.4397, 0.8710, 0.8049, 0.8080, 0.4365, 0.7382, 0.2430, 0.2320, 0.8114,\n",
      "        0.4390, 0.4594, 0.5056, 0.4303, 0.4738, 0.3616, 0.4330, 0.2593, 0.4238,\n",
      "        0.4108, 0.6990, 0.5837, 0.5797, 0.5155, 0.6605, 0.4011, 0.5961, 0.3959,\n",
      "        0.2427, 0.3265, 0.0039])\n",
      "tensor([5.8046e-01, 5.7873e-01, 9.3119e-01, 4.8484e-01, 5.6416e-01, 6.7024e-01,\n",
      "        2.5836e-01, 9.3466e-02, 6.2869e-01, 1.6188e-01, 9.1356e-02, 5.6713e-01,\n",
      "        2.5474e-01, 3.3211e-01, 5.1705e-01, 1.2593e-01, 1.6695e-01, 2.7131e-01,\n",
      "        1.8902e-01, 5.5323e-01, 6.2392e-01, 4.1462e-01, 7.0404e-01, 6.8642e-01,\n",
      "        4.3382e-01, 6.0301e-01, 3.2208e-01, 1.3287e-01, 3.0363e-01, 3.8924e-05])\n",
      "tensor([2.0074e-01, 9.4367e-01, 8.0030e-01, 8.2403e-01, 4.9224e-01, 7.4893e-01,\n",
      "        2.4481e-01, 2.3198e-01, 7.9814e-01, 3.9691e-01, 4.4001e-01, 5.6656e-01,\n",
      "        3.7896e-01, 5.3958e-01, 2.7007e-01, 3.6450e-01, 2.4159e-01, 3.4209e-01,\n",
      "        3.4514e-01, 5.9705e-01, 5.9183e-01, 5.8071e-01, 5.1425e-01, 6.6036e-01,\n",
      "        3.5314e-01, 6.3702e-01, 4.6974e-01, 2.7148e-01, 3.2715e-01, 7.4033e-04])\n",
      "tensor([0.1659, 0.4737, 0.9348, 0.3591, 0.5377, 0.6258, 0.2141, 0.1466, 0.9865,\n",
      "        0.4081, 0.4180, 0.5341, 0.4843, 0.5425, 0.4668, 0.3220, 0.2786, 0.3990,\n",
      "        0.3303, 0.6174, 0.5984, 0.5906, 0.4112, 0.6459, 0.4051, 0.6931, 0.3911,\n",
      "        0.2698, 0.3208, 0.0039])\n",
      "tensor([7.5085e-01, 9.3457e-01, 7.9489e-01, 8.0530e-01, 4.0941e-01, 7.7265e-01,\n",
      "        2.3336e-01, 2.5604e-01, 7.8742e-01, 5.0127e-01, 4.7746e-01, 4.8019e-01,\n",
      "        4.8194e-01, 3.4947e-01, 2.6874e-01, 3.5551e-01, 3.6993e-01, 6.8498e-01,\n",
      "        6.6157e-01, 5.7660e-01, 5.8060e-01, 5.6379e-01, 4.9183e-01, 6.7072e-01,\n",
      "        2.7951e-01, 5.8332e-01, 3.4576e-01, 2.3991e-01, 3.0824e-01, 3.8924e-05])\n",
      "tensor([5.2968e-01, 9.9150e-01, 7.8446e-01, 8.3766e-01, 3.5736e-01, 7.7994e-01,\n",
      "        2.4710e-01, 2.6934e-01, 7.8332e-01, 6.1307e-01, 5.4625e-01, 4.9369e-01,\n",
      "        5.5651e-01, 3.6970e-01, 4.8787e-01, 2.5795e-01, 5.0834e-01, 9.0617e-01,\n",
      "        8.9616e-01, 4.6990e-01, 5.7781e-01, 5.5383e-01, 4.6456e-01, 6.6472e-01,\n",
      "        3.7906e-01, 5.9824e-01, 3.3222e-01, 2.3901e-01, 3.1479e-01, 3.8924e-05])\n",
      "tensor([0.2381, 0.8680, 0.8110, 0.7578, 0.6218, 0.7272, 0.2324, 0.1984, 0.8219,\n",
      "        0.3016, 0.3302, 0.7417, 0.1654, 0.4891, 0.1267, 0.4057, 0.0553, 0.0762,\n",
      "        0.1040, 0.7970, 0.5925, 0.5991, 0.5503, 0.6563, 0.4528, 0.5379, 0.4785,\n",
      "        0.2925, 0.3232, 0.0034])\n",
      "tensor([5.4380e-01, 7.6466e-01, 8.4918e-01, 5.6658e-01, 5.4946e-01, 6.9722e-01,\n",
      "        2.1882e-01, 1.6853e-01, 8.0773e-01, 3.5134e-01, 2.3202e-01, 7.0709e-01,\n",
      "        1.3960e-01, 4.3685e-01, 3.1198e-01, 2.4337e-01, 7.8964e-02, 1.9697e-01,\n",
      "        1.4416e-01, 7.1494e-01, 5.8249e-01, 5.6694e-01, 5.7268e-01, 6.6899e-01,\n",
      "        4.5428e-01, 5.6809e-01, 3.4374e-01, 1.9691e-01, 3.0147e-01, 4.4373e-04])\n",
      "tensor([0.2416, 0.9219, 0.7786, 0.8674, 0.3133, 0.7387, 0.2705, 0.2746, 0.7875,\n",
      "        0.4592, 0.5129, 0.5442, 0.5959, 0.4846, 0.4929, 0.3837, 0.3571, 0.5953,\n",
      "        0.5010, 0.6645, 0.5874, 0.5638, 0.4687, 0.6747, 0.3952, 0.5673, 0.5125,\n",
      "        0.2486, 0.3089, 0.0312])\n",
      "tensor([4.6819e-02, 9.2800e-01, 8.0316e-01, 8.4746e-01, 3.6831e-01, 7.5241e-01,\n",
      "        2.3556e-01, 2.4446e-01, 8.0054e-01, 5.2896e-01, 4.6163e-01, 5.4496e-01,\n",
      "        3.9350e-01, 4.7510e-01, 4.2446e-01, 3.5096e-01, 3.5304e-01, 6.0867e-01,\n",
      "        5.6982e-01, 5.4259e-01, 5.8414e-01, 5.6880e-01, 4.8309e-01, 6.6612e-01,\n",
      "        4.4445e-01, 5.8038e-01, 4.7538e-01, 2.5119e-01, 3.1807e-01, 3.8924e-05])\n",
      "tensor([8.5683e-01, 9.7972e-01, 7.9603e-01, 8.1675e-01, 4.8877e-01, 7.7546e-01,\n",
      "        2.4852e-01, 2.5988e-01, 7.8671e-01, 4.4582e-01, 5.3687e-01, 4.0370e-01,\n",
      "        5.5394e-01, 4.9301e-01, 3.6073e-01, 2.7105e-01, 4.2817e-01, 6.9125e-01,\n",
      "        6.4612e-01, 4.4876e-01, 5.8360e-01, 5.6485e-01, 4.9016e-01, 6.6314e-01,\n",
      "        3.7970e-01, 6.1340e-01, 4.5696e-01, 2.4968e-01, 3.1882e-01, 6.1889e-05])\n",
      "tensor([7.4422e-01, 8.6802e-01, 7.9537e-01, 8.3931e-01, 2.6943e-01, 7.6308e-01,\n",
      "        2.6989e-01, 2.3408e-01, 7.0056e-01, 5.7081e-01, 5.5959e-01, 4.0193e-01,\n",
      "        6.3091e-01, 3.9472e-01, 4.9991e-01, 2.0080e-01, 3.9146e-01, 6.2227e-01,\n",
      "        5.9274e-01, 5.8424e-01, 5.5212e-01, 7.0116e-01, 3.8331e-01, 6.7261e-01,\n",
      "        3.9291e-01, 5.9537e-01, 5.1620e-01, 2.4265e-01, 3.2049e-01, 3.8924e-05])\n",
      "tensor([2.1510e-01, 8.2368e-01, 7.1241e-01, 8.6312e-01, 4.4789e-01, 7.8101e-01,\n",
      "        2.2889e-01, 2.3317e-01, 7.8680e-01, 5.8948e-01, 5.9731e-01, 4.7950e-01,\n",
      "        6.0171e-01, 4.3872e-01, 4.6869e-01, 3.7907e-01, 3.5408e-01, 5.9461e-01,\n",
      "        5.3556e-01, 7.9956e-01, 5.5716e-01, 5.4964e-01, 4.8204e-01, 5.9254e-01,\n",
      "        4.3750e-01, 5.1236e-01, 5.1047e-01, 2.8507e-01, 2.8162e-01, 4.7915e-04])\n",
      "tensor([9.6580e-01, 9.9383e-01, 7.5927e-01, 8.9755e-01, 2.1844e-01, 7.6154e-01,\n",
      "        2.5978e-01, 2.5876e-01, 7.8664e-01, 5.5578e-01, 6.2353e-01, 3.6487e-01,\n",
      "        6.9176e-01, 4.2019e-01, 5.8470e-01, 3.1363e-01, 5.0794e-01, 7.6583e-01,\n",
      "        6.5587e-01, 5.9636e-01, 5.8066e-01, 5.6613e-01, 5.4884e-01, 6.6754e-01,\n",
      "        4.6209e-01, 5.6690e-01, 4.0312e-01, 2.3888e-01, 3.1281e-01, 7.7653e-04])\n",
      "tensor([0.5435, 0.7660, 0.8431, 0.6693, 0.6553, 0.6978, 0.2385, 0.1789, 0.8331,\n",
      "        0.2985, 0.3005, 0.6455, 0.1118, 0.4575, 0.3551, 0.1423, 0.0922, 0.1040,\n",
      "        0.0281, 0.6548, 0.5783, 0.5789, 0.4937, 0.6726, 0.4713, 0.5556, 0.3579,\n",
      "        0.2144, 0.3084, 0.0015])\n",
      "tensor([2.5692e-01, 8.7985e-01, 8.0591e-01, 8.1937e-01, 4.2397e-01, 7.4375e-01,\n",
      "        2.5378e-01, 2.3054e-01, 7.9430e-01, 4.5811e-01, 4.7350e-01, 4.9495e-01,\n",
      "        4.5962e-01, 3.6993e-01, 4.0893e-01, 3.9006e-01, 2.3393e-01, 4.8159e-01,\n",
      "        3.4305e-01, 6.5295e-01, 5.7658e-01, 6.0498e-01, 5.0877e-01, 6.7088e-01,\n",
      "        3.6566e-01, 5.6104e-01, 3.8625e-01, 2.3398e-01, 3.1164e-01, 3.8924e-05])\n",
      "tensor([0.7510, 0.9169, 0.8013, 0.7946, 0.4112, 0.7584, 0.2455, 0.2651, 0.7886,\n",
      "        0.4867, 0.4707, 0.4785, 0.4795, 0.3589, 0.2761, 0.3753, 0.3741, 0.6918,\n",
      "        0.6663, 0.6042, 0.5773, 0.5609, 0.4905, 0.6678, 0.2859, 0.6042, 0.3685,\n",
      "        0.2485, 0.3065, 0.0141])\n",
      "tensor([0.2368, 0.9117, 0.8059, 0.8420, 0.4887, 0.7478, 0.2621, 0.2386, 0.7824,\n",
      "        0.4427, 0.5051, 0.5214, 0.4273, 0.3583, 0.3695, 0.3931, 0.2340, 0.4750,\n",
      "        0.3391, 0.6513, 0.5822, 0.6005, 0.5055, 0.6711, 0.3614, 0.5552, 0.4708,\n",
      "        0.2584, 0.3176, 0.0044])\n",
      "tensor([0.3679, 0.9474, 0.7664, 0.9444, 0.3140, 0.7640, 0.2732, 0.2733, 0.7839,\n",
      "        0.5435, 0.6150, 0.2305, 0.6811, 0.4637, 0.6466, 0.4972, 0.4326, 0.7295,\n",
      "        0.6841, 0.6542, 0.5894, 0.5670, 0.5455, 0.6707, 0.2773, 0.5739, 0.4200,\n",
      "        0.2369, 0.3119, 0.0113])\n",
      "tensor([0.1081, 0.7487, 0.8146, 0.6044, 0.7000, 0.6956, 0.2643, 0.1703, 0.7730,\n",
      "        0.3380, 0.2924, 0.8089, 0.1933, 0.5385, 0.3162, 0.3588, 0.1471, 0.2214,\n",
      "        0.1861, 0.7249, 0.5794, 0.5278, 0.5914, 0.6859, 0.3075, 0.4875, 0.4506,\n",
      "        0.2676, 0.2752, 0.0073])\n",
      "tensor([6.4123e-02, 9.2218e-01, 8.3029e-01, 7.1012e-01, 6.5121e-01, 7.5434e-01,\n",
      "        2.3432e-01, 2.1777e-01, 8.0717e-01, 3.1280e-01, 2.9491e-01, 1.0000e+00,\n",
      "        3.4470e-02, 4.1497e-01, 0.0000e+00, 2.5841e-01, 1.2286e-01, 2.8066e-01,\n",
      "        2.7537e-01, 5.3126e-01, 5.9617e-01, 5.8802e-01, 4.9704e-01, 6.5556e-01,\n",
      "        2.2531e-01, 6.7343e-01, 5.3829e-01, 2.8947e-01, 3.3563e-01, 3.8924e-05])\n",
      "tensor([6.7335e-02, 9.7391e-01, 8.1157e-01, 7.7675e-01, 5.8116e-01, 7.7324e-01,\n",
      "        2.3400e-01, 2.5719e-01, 7.8929e-01, 4.6881e-01, 5.1339e-01, 5.5705e-01,\n",
      "        4.1665e-01, 5.8255e-01, 3.2863e-01, 3.2918e-01, 4.1011e-01, 7.7855e-01,\n",
      "        7.4378e-01, 5.4089e-01, 5.8597e-01, 5.6658e-01, 5.1261e-01, 6.6856e-01,\n",
      "        3.2592e-01, 5.2676e-01, 5.0165e-01, 2.5351e-01, 3.1633e-01, 3.8924e-05])\n",
      "tensor([6.3711e-01, 9.9117e-01, 7.7412e-01, 9.1479e-01, 4.2871e-01, 7.6784e-01,\n",
      "        2.6202e-01, 2.6522e-01, 7.8354e-01, 5.8318e-01, 6.4420e-01, 2.5986e-01,\n",
      "        5.9950e-01, 5.7506e-01, 6.9888e-01, 2.2202e-01, 4.7825e-01, 7.2758e-01,\n",
      "        6.4613e-01, 4.3181e-01, 5.7660e-01, 5.5868e-01, 5.0112e-01, 6.6870e-01,\n",
      "        3.5305e-01, 5.7023e-01, 4.0422e-01, 2.3719e-01, 3.1209e-01, 3.8924e-05])\n",
      "tensor([0.5931, 0.9255, 0.8102, 0.8276, 0.5134, 0.7620, 0.2474, 0.2420, 0.7927,\n",
      "        0.4157, 0.4495, 0.7028, 0.2857, 0.5808, 0.2948, 0.1200, 0.2502, 0.3927,\n",
      "        0.4159, 0.5237, 0.5903, 0.5798, 0.5415, 0.6575, 0.3238, 0.5992, 0.4578,\n",
      "        0.2593, 0.3178, 0.0000])\n",
      "tensor([0.9068, 0.9561, 0.7688, 0.9032, 0.2316, 0.7712, 0.2579, 0.2737, 0.7831,\n",
      "        0.5705, 0.5768, 0.2377, 0.7231, 0.5349, 0.5850, 0.2796, 0.4527, 0.7520,\n",
      "        0.6674, 0.5593, 0.5845, 0.5610, 0.4985, 0.6726, 0.4307, 0.5534, 0.3849,\n",
      "        0.2389, 0.3153, 0.0073])\n",
      "tensor([2.0044e-01, 9.6396e-01, 7.8519e-01, 8.7081e-01, 4.1346e-01, 7.6178e-01,\n",
      "        2.5644e-01, 2.5149e-01, 7.9263e-01, 4.7559e-01, 5.4610e-01, 4.5191e-01,\n",
      "        5.3863e-01, 3.4231e-01, 4.6693e-01, 3.4324e-01, 4.0612e-01, 5.8308e-01,\n",
      "        6.3004e-01, 5.5362e-01, 5.8377e-01, 5.6904e-01, 5.0330e-01, 6.6071e-01,\n",
      "        2.7852e-01, 6.2325e-01, 4.6272e-01, 2.5167e-01, 3.1932e-01, 7.3800e-04])\n",
      "tensor([2.4877e-01, 8.8905e-01, 7.7742e-01, 8.2359e-01, 4.7162e-01, 7.6463e-01,\n",
      "        2.3454e-01, 2.1894e-01, 8.0275e-01, 4.3554e-01, 4.3797e-01, 6.5865e-01,\n",
      "        3.4964e-01, 3.0754e-01, 2.8495e-01, 3.4784e-01, 1.8136e-01, 3.3881e-01,\n",
      "        3.2915e-01, 7.6873e-01, 5.8089e-01, 5.7810e-01, 5.1774e-01, 6.5032e-01,\n",
      "        3.1783e-01, 5.6079e-01, 4.0812e-01, 2.8416e-01, 3.2350e-01, 3.8924e-05])\n",
      "tensor([5.4610e-01, 5.0881e-01, 9.4133e-01, 3.4559e-01, 6.4664e-01, 6.4526e-01,\n",
      "        2.5067e-01, 7.5298e-02, 6.6268e-01, 1.6268e-01, 6.0280e-02, 5.4812e-01,\n",
      "        3.0497e-01, 3.9385e-01, 5.1404e-01, 1.5005e-01, 2.3279e-01, 3.6902e-01,\n",
      "        2.7495e-01, 5.1896e-01, 6.1021e-01, 4.2033e-01, 6.7148e-01, 6.7875e-01,\n",
      "        4.1657e-01, 5.3648e-01, 2.6756e-01, 6.3405e-02, 2.8624e-01, 3.8924e-05])\n",
      "tensor([0.2633, 0.9753, 0.7678, 0.9136, 0.3182, 0.7670, 0.2649, 0.2653, 0.7870,\n",
      "        0.5862, 0.5974, 0.2268, 0.6828, 0.3628, 0.5996, 0.3615, 0.4583, 0.7640,\n",
      "        0.6597, 0.5400, 0.5804, 0.5561, 0.4627, 0.6635, 0.2547, 0.6035, 0.3514,\n",
      "        0.2395, 0.3144, 0.0041])\n",
      "tensor([0.8274, 0.9661, 0.7818, 0.9109, 0.3763, 0.7777, 0.2640, 0.2732, 0.7839,\n",
      "        0.4902, 0.6412, 0.1841, 0.6951, 0.4837, 0.6507, 0.1884, 0.4612, 0.7079,\n",
      "        0.6054, 0.4464, 0.5774, 0.5632, 0.5273, 0.6662, 0.4363, 0.5372, 0.3923,\n",
      "        0.2406, 0.3151, 0.0000])\n",
      "tensor([5.8481e-01, 9.3340e-01, 7.5572e-01, 9.1911e-01, 2.9913e-01, 8.4041e-01,\n",
      "        2.0842e-01, 2.0822e-01, 7.8060e-01, 6.4573e-01, 6.6210e-01, 3.6667e-01,\n",
      "        6.4872e-01, 3.9223e-01, 7.6180e-01, 2.5879e-01, 3.9764e-01, 7.7234e-01,\n",
      "        5.5577e-01, 4.3433e-01, 5.6475e-01, 5.8019e-01, 4.5127e-01, 4.2809e-01,\n",
      "        2.6316e-01, 3.7938e-01, 3.2859e-01, 2.5467e-01, 3.2175e-01, 3.5810e-05])\n",
      "tensor([0.6325, 0.9413, 0.8026, 0.8149, 0.5550, 0.7637, 0.2640, 0.2505, 0.7992,\n",
      "        0.4451, 0.5054, 0.5646, 0.3739, 0.5246, 0.3999, 0.2508, 0.3421, 0.6076,\n",
      "        0.6237, 0.7042, 0.5929, 0.5686, 0.4777, 0.6699, 0.2936, 0.5836, 0.4958,\n",
      "        0.2583, 0.3198, 0.0072])\n",
      "tensor([0.4055, 0.9508, 0.7793, 0.8588, 0.3957, 0.7520, 0.2467, 0.2469, 0.7936,\n",
      "        0.4857, 0.4990, 0.5626, 0.5093, 0.3226, 0.4203, 0.3768, 0.3452, 0.5329,\n",
      "        0.5601, 0.5861, 0.5898, 0.5738, 0.4972, 0.6603, 0.4136, 0.6119, 0.3739,\n",
      "        0.2569, 0.3225, 0.0088])\n",
      "tensor([5.2477e-01, 9.1743e-01, 8.0670e-01, 8.7611e-01, 3.1255e-01, 7.6837e-01,\n",
      "        2.8232e-01, 2.4643e-01, 6.6992e-01, 7.0314e-01, 6.2656e-01, 3.0801e-01,\n",
      "        6.1890e-01, 5.4204e-01, 5.8282e-01, 2.6054e-01, 4.5684e-01, 8.2764e-01,\n",
      "        7.8440e-01, 5.1792e-01, 5.5747e-01, 7.2278e-01, 3.9551e-01, 6.9046e-01,\n",
      "        3.9817e-01, 4.9195e-01, 3.1187e-01, 2.3472e-01, 3.1031e-01, 2.7208e-04])\n",
      "tensor([2.7678e-01, 9.4322e-01, 7.8192e-01, 9.4348e-01, 3.2558e-01, 7.7251e-01,\n",
      "        2.5564e-01, 2.7057e-01, 7.8539e-01, 5.0793e-01, 6.0639e-01, 2.9368e-01,\n",
      "        6.8684e-01, 4.1986e-01, 6.0677e-01, 3.4241e-01, 4.7741e-01, 7.4862e-01,\n",
      "        6.3238e-01, 3.9216e-01, 5.7741e-01, 5.6013e-01, 4.9385e-01, 6.6468e-01,\n",
      "        4.1337e-01, 5.5260e-01, 3.6400e-01, 2.3923e-01, 3.1633e-01, 2.9504e-04])\n",
      "tensor([7.6791e-01, 9.6564e-01, 7.8690e-01, 8.3817e-01, 3.6045e-01, 7.9651e-01,\n",
      "        2.3306e-01, 2.4834e-01, 7.5621e-01, 5.5005e-01, 5.5916e-01, 4.1748e-01,\n",
      "        6.8883e-01, 3.2043e-01, 4.4863e-01, 2.9871e-01, 5.0277e-01, 8.9213e-01,\n",
      "        8.7390e-01, 5.1962e-01, 5.8366e-01, 5.3916e-01, 4.9375e-01, 6.0633e-01,\n",
      "        2.7064e-01, 4.4210e-01, 3.0015e-01, 2.4772e-01, 3.1961e-01, 3.8924e-05])\n",
      "tensor([2.3532e-01, 8.8275e-01, 7.6710e-01, 8.2263e-01, 5.5980e-01, 8.0119e-01,\n",
      "        2.1982e-01, 2.4957e-01, 7.8906e-01, 3.9807e-01, 5.1744e-01, 6.2603e-01,\n",
      "        5.1454e-01, 3.6044e-01, 2.8335e-01, 3.5095e-01, 4.1424e-01, 7.4962e-01,\n",
      "        7.2166e-01, 5.0953e-01, 5.7912e-01, 5.6548e-01, 5.0772e-01, 6.6208e-01,\n",
      "        3.2817e-01, 6.2596e-01, 5.3347e-01, 2.5026e-01, 3.3285e-01, 3.8924e-05])\n",
      "tensor([8.5072e-01, 9.2322e-01, 7.9501e-01, 9.0600e-01, 2.8274e-01, 7.6853e-01,\n",
      "        2.7702e-01, 2.5501e-01, 7.1745e-01, 6.3443e-01, 5.9500e-01, 1.9048e-01,\n",
      "        6.9142e-01, 3.7262e-01, 5.2202e-01, 2.1887e-01, 4.6611e-01, 7.9932e-01,\n",
      "        7.6961e-01, 5.0583e-01, 5.6510e-01, 6.6168e-01, 4.5046e-01, 6.7226e-01,\n",
      "        2.4052e-01, 5.8965e-01, 3.7320e-01, 2.3877e-01, 3.1211e-01, 3.1139e-04])\n",
      "tensor([2.8291e-01, 9.2195e-01, 7.8197e-01, 9.0860e-01, 2.9845e-01, 7.5789e-01,\n",
      "        2.5530e-01, 2.5319e-01, 7.9155e-01, 5.2036e-01, 5.5462e-01, 4.3726e-01,\n",
      "        5.7113e-01, 3.6967e-01, 5.2988e-01, 3.2670e-01, 3.7087e-01, 5.2366e-01,\n",
      "        5.6586e-01, 5.6318e-01, 5.8054e-01, 5.7271e-01, 5.4455e-01, 6.6313e-01,\n",
      "        3.7541e-01, 5.9297e-01, 3.4877e-01, 2.2862e-01, 3.1004e-01, 7.6797e-04])\n",
      "tensor([0.3109, 0.9303, 0.7806, 0.9002, 0.3511, 0.7487, 0.2541, 0.2510, 0.7946,\n",
      "        0.5077, 0.5494, 0.3551, 0.5390, 0.3534, 0.5467, 0.4812, 0.3443, 0.5688,\n",
      "        0.5402, 0.7288, 0.5812, 0.5724, 0.5442, 0.6704, 0.4351, 0.5625, 0.5565,\n",
      "        0.2478, 0.3154, 0.0044])\n",
      "tensor([0.4397, 0.8710, 0.8049, 0.8080, 0.4365, 0.7382, 0.2430, 0.2320, 0.8114,\n",
      "        0.4390, 0.4594, 0.5056, 0.4303, 0.4738, 0.3616, 0.4330, 0.2593, 0.4238,\n",
      "        0.4108, 0.6990, 0.5837, 0.5797, 0.5155, 0.6605, 0.4011, 0.5961, 0.3959,\n",
      "        0.2427, 0.3265, 0.0039])\n",
      "tensor([5.8046e-01, 5.7873e-01, 9.3119e-01, 4.8484e-01, 5.6416e-01, 6.7024e-01,\n",
      "        2.5836e-01, 9.3466e-02, 6.2869e-01, 1.6188e-01, 9.1356e-02, 5.6713e-01,\n",
      "        2.5474e-01, 3.3211e-01, 5.1705e-01, 1.2593e-01, 1.6695e-01, 2.7131e-01,\n",
      "        1.8902e-01, 5.5323e-01, 6.2392e-01, 4.1462e-01, 7.0404e-01, 6.8642e-01,\n",
      "        4.3382e-01, 6.0301e-01, 3.2208e-01, 1.3287e-01, 3.0363e-01, 3.8924e-05])\n",
      "tensor([2.0074e-01, 9.4367e-01, 8.0030e-01, 8.2403e-01, 4.9224e-01, 7.4893e-01,\n",
      "        2.4481e-01, 2.3198e-01, 7.9814e-01, 3.9691e-01, 4.4001e-01, 5.6656e-01,\n",
      "        3.7896e-01, 5.3958e-01, 2.7007e-01, 3.6450e-01, 2.4159e-01, 3.4209e-01,\n",
      "        3.4514e-01, 5.9705e-01, 5.9183e-01, 5.8071e-01, 5.1425e-01, 6.6036e-01,\n",
      "        3.5314e-01, 6.3702e-01, 4.6974e-01, 2.7148e-01, 3.2715e-01, 7.4033e-04])\n",
      "tensor([0.1659, 0.4737, 0.9348, 0.3591, 0.5377, 0.6258, 0.2141, 0.1466, 0.9865,\n",
      "        0.4081, 0.4180, 0.5341, 0.4843, 0.5425, 0.4668, 0.3220, 0.2786, 0.3990,\n",
      "        0.3303, 0.6174, 0.5984, 0.5906, 0.4112, 0.6459, 0.4051, 0.6931, 0.3911,\n",
      "        0.2698, 0.3208, 0.0039])\n",
      "tensor([7.5085e-01, 9.3457e-01, 7.9489e-01, 8.0530e-01, 4.0941e-01, 7.7265e-01,\n",
      "        2.3336e-01, 2.5604e-01, 7.8742e-01, 5.0127e-01, 4.7746e-01, 4.8019e-01,\n",
      "        4.8194e-01, 3.4947e-01, 2.6874e-01, 3.5551e-01, 3.6993e-01, 6.8498e-01,\n",
      "        6.6157e-01, 5.7660e-01, 5.8060e-01, 5.6379e-01, 4.9183e-01, 6.7072e-01,\n",
      "        2.7951e-01, 5.8332e-01, 3.4576e-01, 2.3991e-01, 3.0824e-01, 3.8924e-05])\n",
      "tensor([5.2968e-01, 9.9150e-01, 7.8446e-01, 8.3766e-01, 3.5736e-01, 7.7994e-01,\n",
      "        2.4710e-01, 2.6934e-01, 7.8332e-01, 6.1307e-01, 5.4625e-01, 4.9369e-01,\n",
      "        5.5651e-01, 3.6970e-01, 4.8787e-01, 2.5795e-01, 5.0834e-01, 9.0617e-01,\n",
      "        8.9616e-01, 4.6990e-01, 5.7781e-01, 5.5383e-01, 4.6456e-01, 6.6472e-01,\n",
      "        3.7906e-01, 5.9824e-01, 3.3222e-01, 2.3901e-01, 3.1479e-01, 3.8924e-05])\n",
      "tensor([0.2381, 0.8680, 0.8110, 0.7578, 0.6218, 0.7272, 0.2324, 0.1984, 0.8219,\n",
      "        0.3016, 0.3302, 0.7417, 0.1654, 0.4891, 0.1267, 0.4057, 0.0553, 0.0762,\n",
      "        0.1040, 0.7970, 0.5925, 0.5991, 0.5503, 0.6563, 0.4528, 0.5379, 0.4785,\n",
      "        0.2925, 0.3232, 0.0034])\n",
      "tensor([5.4380e-01, 7.6466e-01, 8.4918e-01, 5.6658e-01, 5.4946e-01, 6.9722e-01,\n",
      "        2.1882e-01, 1.6853e-01, 8.0773e-01, 3.5134e-01, 2.3202e-01, 7.0709e-01,\n",
      "        1.3960e-01, 4.3685e-01, 3.1198e-01, 2.4337e-01, 7.8964e-02, 1.9697e-01,\n",
      "        1.4416e-01, 7.1494e-01, 5.8249e-01, 5.6694e-01, 5.7268e-01, 6.6899e-01,\n",
      "        4.5428e-01, 5.6809e-01, 3.4374e-01, 1.9691e-01, 3.0147e-01, 4.4373e-04])\n",
      "tensor([0.2416, 0.9219, 0.7786, 0.8674, 0.3133, 0.7387, 0.2705, 0.2746, 0.7875,\n",
      "        0.4592, 0.5129, 0.5442, 0.5959, 0.4846, 0.4929, 0.3837, 0.3571, 0.5953,\n",
      "        0.5010, 0.6645, 0.5874, 0.5638, 0.4687, 0.6747, 0.3952, 0.5673, 0.5125,\n",
      "        0.2486, 0.3089, 0.0312])\n",
      "tensor([4.6819e-02, 9.2800e-01, 8.0316e-01, 8.4746e-01, 3.6831e-01, 7.5241e-01,\n",
      "        2.3556e-01, 2.4446e-01, 8.0054e-01, 5.2896e-01, 4.6163e-01, 5.4496e-01,\n",
      "        3.9350e-01, 4.7510e-01, 4.2446e-01, 3.5096e-01, 3.5304e-01, 6.0867e-01,\n",
      "        5.6982e-01, 5.4259e-01, 5.8414e-01, 5.6880e-01, 4.8309e-01, 6.6612e-01,\n",
      "        4.4445e-01, 5.8038e-01, 4.7538e-01, 2.5119e-01, 3.1807e-01, 3.8924e-05])\n",
      "tensor([8.5683e-01, 9.7972e-01, 7.9603e-01, 8.1675e-01, 4.8877e-01, 7.7546e-01,\n",
      "        2.4852e-01, 2.5988e-01, 7.8671e-01, 4.4582e-01, 5.3687e-01, 4.0370e-01,\n",
      "        5.5394e-01, 4.9301e-01, 3.6073e-01, 2.7105e-01, 4.2817e-01, 6.9125e-01,\n",
      "        6.4612e-01, 4.4876e-01, 5.8360e-01, 5.6485e-01, 4.9016e-01, 6.6314e-01,\n",
      "        3.7970e-01, 6.1340e-01, 4.5696e-01, 2.4968e-01, 3.1882e-01, 6.1889e-05])\n",
      "tensor([7.4422e-01, 8.6802e-01, 7.9537e-01, 8.3931e-01, 2.6943e-01, 7.6308e-01,\n",
      "        2.6989e-01, 2.3408e-01, 7.0056e-01, 5.7081e-01, 5.5959e-01, 4.0193e-01,\n",
      "        6.3091e-01, 3.9472e-01, 4.9991e-01, 2.0080e-01, 3.9146e-01, 6.2227e-01,\n",
      "        5.9274e-01, 5.8424e-01, 5.5212e-01, 7.0116e-01, 3.8331e-01, 6.7261e-01,\n",
      "        3.9291e-01, 5.9537e-01, 5.1620e-01, 2.4265e-01, 3.2049e-01, 3.8924e-05])\n",
      "tensor([2.1510e-01, 8.2368e-01, 7.1241e-01, 8.6312e-01, 4.4789e-01, 7.8101e-01,\n",
      "        2.2889e-01, 2.3317e-01, 7.8680e-01, 5.8948e-01, 5.9731e-01, 4.7950e-01,\n",
      "        6.0171e-01, 4.3872e-01, 4.6869e-01, 3.7907e-01, 3.5408e-01, 5.9461e-01,\n",
      "        5.3556e-01, 7.9956e-01, 5.5716e-01, 5.4964e-01, 4.8204e-01, 5.9254e-01,\n",
      "        4.3750e-01, 5.1236e-01, 5.1047e-01, 2.8507e-01, 2.8162e-01, 4.7915e-04])\n",
      "tensor([9.6580e-01, 9.9383e-01, 7.5927e-01, 8.9755e-01, 2.1844e-01, 7.6154e-01,\n",
      "        2.5978e-01, 2.5876e-01, 7.8664e-01, 5.5578e-01, 6.2353e-01, 3.6487e-01,\n",
      "        6.9176e-01, 4.2019e-01, 5.8470e-01, 3.1363e-01, 5.0794e-01, 7.6583e-01,\n",
      "        6.5587e-01, 5.9636e-01, 5.8066e-01, 5.6613e-01, 5.4884e-01, 6.6754e-01,\n",
      "        4.6209e-01, 5.6690e-01, 4.0312e-01, 2.3888e-01, 3.1281e-01, 7.7653e-04])\n",
      "tensor([0.5435, 0.7660, 0.8431, 0.6693, 0.6553, 0.6978, 0.2385, 0.1789, 0.8331,\n",
      "        0.2985, 0.3005, 0.6455, 0.1118, 0.4575, 0.3551, 0.1423, 0.0922, 0.1040,\n",
      "        0.0281, 0.6548, 0.5783, 0.5789, 0.4937, 0.6726, 0.4713, 0.5556, 0.3579,\n",
      "        0.2144, 0.3084, 0.0015])\n",
      "tensor([2.5692e-01, 8.7985e-01, 8.0591e-01, 8.1937e-01, 4.2397e-01, 7.4375e-01,\n",
      "        2.5378e-01, 2.3054e-01, 7.9430e-01, 4.5811e-01, 4.7350e-01, 4.9495e-01,\n",
      "        4.5962e-01, 3.6993e-01, 4.0893e-01, 3.9006e-01, 2.3393e-01, 4.8159e-01,\n",
      "        3.4305e-01, 6.5295e-01, 5.7658e-01, 6.0498e-01, 5.0877e-01, 6.7088e-01,\n",
      "        3.6566e-01, 5.6104e-01, 3.8625e-01, 2.3398e-01, 3.1164e-01, 3.8924e-05])\n",
      "tensor([0.7510, 0.9169, 0.8013, 0.7946, 0.4112, 0.7584, 0.2455, 0.2651, 0.7886,\n",
      "        0.4867, 0.4707, 0.4785, 0.4795, 0.3589, 0.2761, 0.3753, 0.3741, 0.6918,\n",
      "        0.6663, 0.6042, 0.5773, 0.5609, 0.4905, 0.6678, 0.2859, 0.6042, 0.3685,\n",
      "        0.2485, 0.3065, 0.0141])\n",
      "tensor([0.2368, 0.9117, 0.8059, 0.8420, 0.4887, 0.7478, 0.2621, 0.2386, 0.7824,\n",
      "        0.4427, 0.5051, 0.5214, 0.4273, 0.3583, 0.3695, 0.3931, 0.2340, 0.4750,\n",
      "        0.3391, 0.6513, 0.5822, 0.6005, 0.5055, 0.6711, 0.3614, 0.5552, 0.4708,\n",
      "        0.2584, 0.3176, 0.0044])\n",
      "tensor([0.3679, 0.9474, 0.7664, 0.9444, 0.3140, 0.7640, 0.2732, 0.2733, 0.7839,\n",
      "        0.5435, 0.6150, 0.2305, 0.6811, 0.4637, 0.6466, 0.4972, 0.4326, 0.7295,\n",
      "        0.6841, 0.6542, 0.5894, 0.5670, 0.5455, 0.6707, 0.2773, 0.5739, 0.4200,\n",
      "        0.2369, 0.3119, 0.0113])\n",
      "tensor([0.1081, 0.7487, 0.8146, 0.6044, 0.7000, 0.6956, 0.2643, 0.1703, 0.7730,\n",
      "        0.3380, 0.2924, 0.8089, 0.1933, 0.5385, 0.3162, 0.3588, 0.1471, 0.2214,\n",
      "        0.1861, 0.7249, 0.5794, 0.5278, 0.5914, 0.6859, 0.3075, 0.4875, 0.4506,\n",
      "        0.2676, 0.2752, 0.0073])\n",
      "tensor([6.4123e-02, 9.2218e-01, 8.3029e-01, 7.1012e-01, 6.5121e-01, 7.5434e-01,\n",
      "        2.3432e-01, 2.1777e-01, 8.0717e-01, 3.1280e-01, 2.9491e-01, 1.0000e+00,\n",
      "        3.4470e-02, 4.1497e-01, 0.0000e+00, 2.5841e-01, 1.2286e-01, 2.8066e-01,\n",
      "        2.7537e-01, 5.3126e-01, 5.9617e-01, 5.8802e-01, 4.9704e-01, 6.5556e-01,\n",
      "        2.2531e-01, 6.7343e-01, 5.3829e-01, 2.8947e-01, 3.3563e-01, 3.8924e-05])\n",
      "tensor([6.7335e-02, 9.7391e-01, 8.1157e-01, 7.7675e-01, 5.8116e-01, 7.7324e-01,\n",
      "        2.3400e-01, 2.5719e-01, 7.8929e-01, 4.6881e-01, 5.1339e-01, 5.5705e-01,\n",
      "        4.1665e-01, 5.8255e-01, 3.2863e-01, 3.2918e-01, 4.1011e-01, 7.7855e-01,\n",
      "        7.4378e-01, 5.4089e-01, 5.8597e-01, 5.6658e-01, 5.1261e-01, 6.6856e-01,\n",
      "        3.2592e-01, 5.2676e-01, 5.0165e-01, 2.5351e-01, 3.1633e-01, 3.8924e-05])\n",
      "tensor([6.3711e-01, 9.9117e-01, 7.7412e-01, 9.1479e-01, 4.2871e-01, 7.6784e-01,\n",
      "        2.6202e-01, 2.6522e-01, 7.8354e-01, 5.8318e-01, 6.4420e-01, 2.5986e-01,\n",
      "        5.9950e-01, 5.7506e-01, 6.9888e-01, 2.2202e-01, 4.7825e-01, 7.2758e-01,\n",
      "        6.4613e-01, 4.3181e-01, 5.7660e-01, 5.5868e-01, 5.0112e-01, 6.6870e-01,\n",
      "        3.5305e-01, 5.7023e-01, 4.0422e-01, 2.3719e-01, 3.1209e-01, 3.8924e-05])\n",
      "tensor([0.5931, 0.9255, 0.8102, 0.8276, 0.5134, 0.7620, 0.2474, 0.2420, 0.7927,\n",
      "        0.4157, 0.4495, 0.7028, 0.2857, 0.5808, 0.2948, 0.1200, 0.2502, 0.3927,\n",
      "        0.4159, 0.5237, 0.5903, 0.5798, 0.5415, 0.6575, 0.3238, 0.5992, 0.4578,\n",
      "        0.2593, 0.3178, 0.0000])\n",
      "tensor([0.9068, 0.9561, 0.7688, 0.9032, 0.2316, 0.7712, 0.2579, 0.2737, 0.7831,\n",
      "        0.5705, 0.5768, 0.2377, 0.7231, 0.5349, 0.5850, 0.2796, 0.4527, 0.7520,\n",
      "        0.6674, 0.5593, 0.5845, 0.5610, 0.4985, 0.6726, 0.4307, 0.5534, 0.3849,\n",
      "        0.2389, 0.3153, 0.0073])\n",
      "tensor([2.0044e-01, 9.6396e-01, 7.8519e-01, 8.7081e-01, 4.1346e-01, 7.6178e-01,\n",
      "        2.5644e-01, 2.5149e-01, 7.9263e-01, 4.7559e-01, 5.4610e-01, 4.5191e-01,\n",
      "        5.3863e-01, 3.4231e-01, 4.6693e-01, 3.4324e-01, 4.0612e-01, 5.8308e-01,\n",
      "        6.3004e-01, 5.5362e-01, 5.8377e-01, 5.6904e-01, 5.0330e-01, 6.6071e-01,\n",
      "        2.7852e-01, 6.2325e-01, 4.6272e-01, 2.5167e-01, 3.1932e-01, 7.3800e-04])\n",
      "tensor([2.4877e-01, 8.8905e-01, 7.7742e-01, 8.2359e-01, 4.7162e-01, 7.6463e-01,\n",
      "        2.3454e-01, 2.1894e-01, 8.0275e-01, 4.3554e-01, 4.3797e-01, 6.5865e-01,\n",
      "        3.4964e-01, 3.0754e-01, 2.8495e-01, 3.4784e-01, 1.8136e-01, 3.3881e-01,\n",
      "        3.2915e-01, 7.6873e-01, 5.8089e-01, 5.7810e-01, 5.1774e-01, 6.5032e-01,\n",
      "        3.1783e-01, 5.6079e-01, 4.0812e-01, 2.8416e-01, 3.2350e-01, 3.8924e-05])\n",
      "tensor([5.4610e-01, 5.0881e-01, 9.4133e-01, 3.4559e-01, 6.4664e-01, 6.4526e-01,\n",
      "        2.5067e-01, 7.5298e-02, 6.6268e-01, 1.6268e-01, 6.0280e-02, 5.4812e-01,\n",
      "        3.0497e-01, 3.9385e-01, 5.1404e-01, 1.5005e-01, 2.3279e-01, 3.6902e-01,\n",
      "        2.7495e-01, 5.1896e-01, 6.1021e-01, 4.2033e-01, 6.7148e-01, 6.7875e-01,\n",
      "        4.1657e-01, 5.3648e-01, 2.6756e-01, 6.3405e-02, 2.8624e-01, 3.8924e-05])\n",
      "tensor([0.2633, 0.9753, 0.7678, 0.9136, 0.3182, 0.7670, 0.2649, 0.2653, 0.7870,\n",
      "        0.5862, 0.5974, 0.2268, 0.6828, 0.3628, 0.5996, 0.3615, 0.4583, 0.7640,\n",
      "        0.6597, 0.5400, 0.5804, 0.5561, 0.4627, 0.6635, 0.2547, 0.6035, 0.3514,\n",
      "        0.2395, 0.3144, 0.0041])\n",
      "tensor([0.8274, 0.9661, 0.7818, 0.9109, 0.3763, 0.7777, 0.2640, 0.2732, 0.7839,\n",
      "        0.4902, 0.6412, 0.1841, 0.6951, 0.4837, 0.6507, 0.1884, 0.4612, 0.7079,\n",
      "        0.6054, 0.4464, 0.5774, 0.5632, 0.5273, 0.6662, 0.4363, 0.5372, 0.3923,\n",
      "        0.2406, 0.3151, 0.0000])\n",
      "tensor([5.8481e-01, 9.3340e-01, 7.5572e-01, 9.1911e-01, 2.9913e-01, 8.4041e-01,\n",
      "        2.0842e-01, 2.0822e-01, 7.8060e-01, 6.4573e-01, 6.6210e-01, 3.6667e-01,\n",
      "        6.4872e-01, 3.9223e-01, 7.6180e-01, 2.5879e-01, 3.9764e-01, 7.7234e-01,\n",
      "        5.5577e-01, 4.3433e-01, 5.6475e-01, 5.8019e-01, 4.5127e-01, 4.2809e-01,\n",
      "        2.6316e-01, 3.7938e-01, 3.2859e-01, 2.5467e-01, 3.2175e-01, 3.5810e-05])\n",
      "tensor([0.6325, 0.9413, 0.8026, 0.8149, 0.5550, 0.7637, 0.2640, 0.2505, 0.7992,\n",
      "        0.4451, 0.5054, 0.5646, 0.3739, 0.5246, 0.3999, 0.2508, 0.3421, 0.6076,\n",
      "        0.6237, 0.7042, 0.5929, 0.5686, 0.4777, 0.6699, 0.2936, 0.5836, 0.4958,\n",
      "        0.2583, 0.3198, 0.0072])\n",
      "tensor([0.4055, 0.9508, 0.7793, 0.8588, 0.3957, 0.7520, 0.2467, 0.2469, 0.7936,\n",
      "        0.4857, 0.4990, 0.5626, 0.5093, 0.3226, 0.4203, 0.3768, 0.3452, 0.5329,\n",
      "        0.5601, 0.5861, 0.5898, 0.5738, 0.4972, 0.6603, 0.4136, 0.6119, 0.3739,\n",
      "        0.2569, 0.3225, 0.0088])\n",
      "tensor([5.2477e-01, 9.1743e-01, 8.0670e-01, 8.7611e-01, 3.1255e-01, 7.6837e-01,\n",
      "        2.8232e-01, 2.4643e-01, 6.6992e-01, 7.0314e-01, 6.2656e-01, 3.0801e-01,\n",
      "        6.1890e-01, 5.4204e-01, 5.8282e-01, 2.6054e-01, 4.5684e-01, 8.2764e-01,\n",
      "        7.8440e-01, 5.1792e-01, 5.5747e-01, 7.2278e-01, 3.9551e-01, 6.9046e-01,\n",
      "        3.9817e-01, 4.9195e-01, 3.1187e-01, 2.3472e-01, 3.1031e-01, 2.7208e-04])\n",
      "tensor([2.7678e-01, 9.4322e-01, 7.8192e-01, 9.4348e-01, 3.2558e-01, 7.7251e-01,\n",
      "        2.5564e-01, 2.7057e-01, 7.8539e-01, 5.0793e-01, 6.0639e-01, 2.9368e-01,\n",
      "        6.8684e-01, 4.1986e-01, 6.0677e-01, 3.4241e-01, 4.7741e-01, 7.4862e-01,\n",
      "        6.3238e-01, 3.9216e-01, 5.7741e-01, 5.6013e-01, 4.9385e-01, 6.6468e-01,\n",
      "        4.1337e-01, 5.5260e-01, 3.6400e-01, 2.3923e-01, 3.1633e-01, 2.9504e-04])\n",
      "tensor([7.6791e-01, 9.6564e-01, 7.8690e-01, 8.3817e-01, 3.6045e-01, 7.9651e-01,\n",
      "        2.3306e-01, 2.4834e-01, 7.5621e-01, 5.5005e-01, 5.5916e-01, 4.1748e-01,\n",
      "        6.8883e-01, 3.2043e-01, 4.4863e-01, 2.9871e-01, 5.0277e-01, 8.9213e-01,\n",
      "        8.7390e-01, 5.1962e-01, 5.8366e-01, 5.3916e-01, 4.9375e-01, 6.0633e-01,\n",
      "        2.7064e-01, 4.4210e-01, 3.0015e-01, 2.4772e-01, 3.1961e-01, 3.8924e-05])\n",
      "tensor([2.3532e-01, 8.8275e-01, 7.6710e-01, 8.2263e-01, 5.5980e-01, 8.0119e-01,\n",
      "        2.1982e-01, 2.4957e-01, 7.8906e-01, 3.9807e-01, 5.1744e-01, 6.2603e-01,\n",
      "        5.1454e-01, 3.6044e-01, 2.8335e-01, 3.5095e-01, 4.1424e-01, 7.4962e-01,\n",
      "        7.2166e-01, 5.0953e-01, 5.7912e-01, 5.6548e-01, 5.0772e-01, 6.6208e-01,\n",
      "        3.2817e-01, 6.2596e-01, 5.3347e-01, 2.5026e-01, 3.3285e-01, 3.8924e-05])\n",
      "tensor([8.5072e-01, 9.2322e-01, 7.9501e-01, 9.0600e-01, 2.8274e-01, 7.6853e-01,\n",
      "        2.7702e-01, 2.5501e-01, 7.1745e-01, 6.3443e-01, 5.9500e-01, 1.9048e-01,\n",
      "        6.9142e-01, 3.7262e-01, 5.2202e-01, 2.1887e-01, 4.6611e-01, 7.9932e-01,\n",
      "        7.6961e-01, 5.0583e-01, 5.6510e-01, 6.6168e-01, 4.5046e-01, 6.7226e-01,\n",
      "        2.4052e-01, 5.8965e-01, 3.7320e-01, 2.3877e-01, 3.1211e-01, 3.1139e-04])\n",
      "tensor([2.8291e-01, 9.2195e-01, 7.8197e-01, 9.0860e-01, 2.9845e-01, 7.5789e-01,\n",
      "        2.5530e-01, 2.5319e-01, 7.9155e-01, 5.2036e-01, 5.5462e-01, 4.3726e-01,\n",
      "        5.7113e-01, 3.6967e-01, 5.2988e-01, 3.2670e-01, 3.7087e-01, 5.2366e-01,\n",
      "        5.6586e-01, 5.6318e-01, 5.8054e-01, 5.7271e-01, 5.4455e-01, 6.6313e-01,\n",
      "        3.7541e-01, 5.9297e-01, 3.4877e-01, 2.2862e-01, 3.1004e-01, 7.6797e-04])\n",
      "tensor([0.3109, 0.9303, 0.7806, 0.9002, 0.3511, 0.7487, 0.2541, 0.2510, 0.7946,\n",
      "        0.5077, 0.5494, 0.3551, 0.5390, 0.3534, 0.5467, 0.4812, 0.3443, 0.5688,\n",
      "        0.5402, 0.7288, 0.5812, 0.5724, 0.5442, 0.6704, 0.4351, 0.5625, 0.5565,\n",
      "        0.2478, 0.3154, 0.0044])\n",
      "tensor([0.4397, 0.8710, 0.8049, 0.8080, 0.4365, 0.7382, 0.2430, 0.2320, 0.8114,\n",
      "        0.4390, 0.4594, 0.5056, 0.4303, 0.4738, 0.3616, 0.4330, 0.2593, 0.4238,\n",
      "        0.4108, 0.6990, 0.5837, 0.5797, 0.5155, 0.6605, 0.4011, 0.5961, 0.3959,\n",
      "        0.2427, 0.3265, 0.0039])\n",
      "tensor([5.8046e-01, 5.7873e-01, 9.3119e-01, 4.8484e-01, 5.6416e-01, 6.7024e-01,\n",
      "        2.5836e-01, 9.3466e-02, 6.2869e-01, 1.6188e-01, 9.1356e-02, 5.6713e-01,\n",
      "        2.5474e-01, 3.3211e-01, 5.1705e-01, 1.2593e-01, 1.6695e-01, 2.7131e-01,\n",
      "        1.8902e-01, 5.5323e-01, 6.2392e-01, 4.1462e-01, 7.0404e-01, 6.8642e-01,\n",
      "        4.3382e-01, 6.0301e-01, 3.2208e-01, 1.3287e-01, 3.0363e-01, 3.8924e-05])\n",
      "tensor([2.0074e-01, 9.4367e-01, 8.0030e-01, 8.2403e-01, 4.9224e-01, 7.4893e-01,\n",
      "        2.4481e-01, 2.3198e-01, 7.9814e-01, 3.9691e-01, 4.4001e-01, 5.6656e-01,\n",
      "        3.7896e-01, 5.3958e-01, 2.7007e-01, 3.6450e-01, 2.4159e-01, 3.4209e-01,\n",
      "        3.4514e-01, 5.9705e-01, 5.9183e-01, 5.8071e-01, 5.1425e-01, 6.6036e-01,\n",
      "        3.5314e-01, 6.3702e-01, 4.6974e-01, 2.7148e-01, 3.2715e-01, 7.4033e-04])\n",
      "tensor([0.1659, 0.4737, 0.9348, 0.3591, 0.5377, 0.6258, 0.2141, 0.1466, 0.9865,\n",
      "        0.4081, 0.4180, 0.5341, 0.4843, 0.5425, 0.4668, 0.3220, 0.2786, 0.3990,\n",
      "        0.3303, 0.6174, 0.5984, 0.5906, 0.4112, 0.6459, 0.4051, 0.6931, 0.3911,\n",
      "        0.2698, 0.3208, 0.0039])\n",
      "tensor([7.5085e-01, 9.3457e-01, 7.9489e-01, 8.0530e-01, 4.0941e-01, 7.7265e-01,\n",
      "        2.3336e-01, 2.5604e-01, 7.8742e-01, 5.0127e-01, 4.7746e-01, 4.8019e-01,\n",
      "        4.8194e-01, 3.4947e-01, 2.6874e-01, 3.5551e-01, 3.6993e-01, 6.8498e-01,\n",
      "        6.6157e-01, 5.7660e-01, 5.8060e-01, 5.6379e-01, 4.9183e-01, 6.7072e-01,\n",
      "        2.7951e-01, 5.8332e-01, 3.4576e-01, 2.3991e-01, 3.0824e-01, 3.8924e-05])\n",
      "tensor([5.2968e-01, 9.9150e-01, 7.8446e-01, 8.3766e-01, 3.5736e-01, 7.7994e-01,\n",
      "        2.4710e-01, 2.6934e-01, 7.8332e-01, 6.1307e-01, 5.4625e-01, 4.9369e-01,\n",
      "        5.5651e-01, 3.6970e-01, 4.8787e-01, 2.5795e-01, 5.0834e-01, 9.0617e-01,\n",
      "        8.9616e-01, 4.6990e-01, 5.7781e-01, 5.5383e-01, 4.6456e-01, 6.6472e-01,\n",
      "        3.7906e-01, 5.9824e-01, 3.3222e-01, 2.3901e-01, 3.1479e-01, 3.8924e-05])\n",
      "tensor([0.2381, 0.8680, 0.8110, 0.7578, 0.6218, 0.7272, 0.2324, 0.1984, 0.8219,\n",
      "        0.3016, 0.3302, 0.7417, 0.1654, 0.4891, 0.1267, 0.4057, 0.0553, 0.0762,\n",
      "        0.1040, 0.7970, 0.5925, 0.5991, 0.5503, 0.6563, 0.4528, 0.5379, 0.4785,\n",
      "        0.2925, 0.3232, 0.0034])\n",
      "tensor([5.4380e-01, 7.6466e-01, 8.4918e-01, 5.6658e-01, 5.4946e-01, 6.9722e-01,\n",
      "        2.1882e-01, 1.6853e-01, 8.0773e-01, 3.5134e-01, 2.3202e-01, 7.0709e-01,\n",
      "        1.3960e-01, 4.3685e-01, 3.1198e-01, 2.4337e-01, 7.8964e-02, 1.9697e-01,\n",
      "        1.4416e-01, 7.1494e-01, 5.8249e-01, 5.6694e-01, 5.7268e-01, 6.6899e-01,\n",
      "        4.5428e-01, 5.6809e-01, 3.4374e-01, 1.9691e-01, 3.0147e-01, 4.4373e-04])\n",
      "tensor([0.2416, 0.9219, 0.7786, 0.8674, 0.3133, 0.7387, 0.2705, 0.2746, 0.7875,\n",
      "        0.4592, 0.5129, 0.5442, 0.5959, 0.4846, 0.4929, 0.3837, 0.3571, 0.5953,\n",
      "        0.5010, 0.6645, 0.5874, 0.5638, 0.4687, 0.6747, 0.3952, 0.5673, 0.5125,\n",
      "        0.2486, 0.3089, 0.0312])\n",
      "tensor([4.6819e-02, 9.2800e-01, 8.0316e-01, 8.4746e-01, 3.6831e-01, 7.5241e-01,\n",
      "        2.3556e-01, 2.4446e-01, 8.0054e-01, 5.2896e-01, 4.6163e-01, 5.4496e-01,\n",
      "        3.9350e-01, 4.7510e-01, 4.2446e-01, 3.5096e-01, 3.5304e-01, 6.0867e-01,\n",
      "        5.6982e-01, 5.4259e-01, 5.8414e-01, 5.6880e-01, 4.8309e-01, 6.6612e-01,\n",
      "        4.4445e-01, 5.8038e-01, 4.7538e-01, 2.5119e-01, 3.1807e-01, 3.8924e-05])\n",
      "tensor([8.5683e-01, 9.7972e-01, 7.9603e-01, 8.1675e-01, 4.8877e-01, 7.7546e-01,\n",
      "        2.4852e-01, 2.5988e-01, 7.8671e-01, 4.4582e-01, 5.3687e-01, 4.0370e-01,\n",
      "        5.5394e-01, 4.9301e-01, 3.6073e-01, 2.7105e-01, 4.2817e-01, 6.9125e-01,\n",
      "        6.4612e-01, 4.4876e-01, 5.8360e-01, 5.6485e-01, 4.9016e-01, 6.6314e-01,\n",
      "        3.7970e-01, 6.1340e-01, 4.5696e-01, 2.4968e-01, 3.1882e-01, 6.1889e-05])\n",
      "tensor([7.4422e-01, 8.6802e-01, 7.9537e-01, 8.3931e-01, 2.6943e-01, 7.6308e-01,\n",
      "        2.6989e-01, 2.3408e-01, 7.0056e-01, 5.7081e-01, 5.5959e-01, 4.0193e-01,\n",
      "        6.3091e-01, 3.9472e-01, 4.9991e-01, 2.0080e-01, 3.9146e-01, 6.2227e-01,\n",
      "        5.9274e-01, 5.8424e-01, 5.5212e-01, 7.0116e-01, 3.8331e-01, 6.7261e-01,\n",
      "        3.9291e-01, 5.9537e-01, 5.1620e-01, 2.4265e-01, 3.2049e-01, 3.8924e-05])\n",
      "tensor([2.1510e-01, 8.2368e-01, 7.1241e-01, 8.6312e-01, 4.4789e-01, 7.8101e-01,\n",
      "        2.2889e-01, 2.3317e-01, 7.8680e-01, 5.8948e-01, 5.9731e-01, 4.7950e-01,\n",
      "        6.0171e-01, 4.3872e-01, 4.6869e-01, 3.7907e-01, 3.5408e-01, 5.9461e-01,\n",
      "        5.3556e-01, 7.9956e-01, 5.5716e-01, 5.4964e-01, 4.8204e-01, 5.9254e-01,\n",
      "        4.3750e-01, 5.1236e-01, 5.1047e-01, 2.8507e-01, 2.8162e-01, 4.7915e-04])\n",
      "It took  0.33914875984191895\n"
     ]
    }
   ],
   "source": [
    "losses = vae.trainVAE(dataloader, num_epochs=5, data_dim = dataloader.dataset.features.size(1),feature_cols=feature_cols)#, embeddingDim=128, compressDims=(128, 128), decompressDims=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgblosses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b8672e07ac7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgblosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xgblosses' is not defined"
     ]
    }
   ],
   "source": [
    "xgblosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0.68020305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(xgblosses.size):\n",
    "    if np.round(xgblosses[i],8) == number:\n",
    "        print(i*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788323.4552154541"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedData = TESTVAE.generate(n=500, num_epochs=100000, epoch=10,data_dim=30,embeddingDim=128, compressDims=(128, 128), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generatedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'xgblosses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-169d7cb863f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgblosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Vanilla GAN - XGB Accuracy During Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgblosses' is not defined"
     ]
    }
   ],
   "source": [
    "# print(min(xgblosses))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(f\"Vanilla GAN - Generator and Discriminator Loss During Training\")\n",
    "plt.plot(losses,label=\"G\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "# plt.savefig(f'reports/figures/gan/GAN.png')\n",
    "plt.show()\n",
    "\n",
    "w = 10\n",
    "a = pd.DataFrame(xgblosses[:]).rolling(w).mean()\n",
    "plt.title(f\"Vanilla GAN - XGB Accuracy During Training\")\n",
    "plt.plot(a)\n",
    "# plt.savefig(f'reports/figures/gan/xgblosses_GAN.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount=train.shape[0]\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227845"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.ones((more_data.shape[0],more_data.shape[1]+1))\n",
    "b[:,:-1] = more_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.776999</td>\n",
       "      <td>3.268421</td>\n",
       "      <td>-5.375220</td>\n",
       "      <td>4.764702</td>\n",
       "      <td>-4.173685</td>\n",
       "      <td>-1.467518</td>\n",
       "      <td>-6.940997</td>\n",
       "      <td>2.625346</td>\n",
       "      <td>-4.231784</td>\n",
       "      <td>-7.443864</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282930</td>\n",
       "      <td>-0.091298</td>\n",
       "      <td>-0.290909</td>\n",
       "      <td>-0.760151</td>\n",
       "      <td>0.119505</td>\n",
       "      <td>0.233282</td>\n",
       "      <td>0.801211</td>\n",
       "      <td>-0.007126</td>\n",
       "      <td>-0.711648</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.401826</td>\n",
       "      <td>-3.901563</td>\n",
       "      <td>-1.627244</td>\n",
       "      <td>-1.415839</td>\n",
       "      <td>1.568214</td>\n",
       "      <td>-0.209140</td>\n",
       "      <td>2.603787</td>\n",
       "      <td>-1.345410</td>\n",
       "      <td>-0.239516</td>\n",
       "      <td>1.843090</td>\n",
       "      <td>...</td>\n",
       "      <td>1.041632</td>\n",
       "      <td>0.432413</td>\n",
       "      <td>0.311427</td>\n",
       "      <td>-2.418743</td>\n",
       "      <td>-0.454784</td>\n",
       "      <td>1.797837</td>\n",
       "      <td>0.206162</td>\n",
       "      <td>-0.010513</td>\n",
       "      <td>602.939148</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.904875</td>\n",
       "      <td>1.227296</td>\n",
       "      <td>-8.476022</td>\n",
       "      <td>2.107618</td>\n",
       "      <td>-4.752575</td>\n",
       "      <td>-0.844691</td>\n",
       "      <td>-0.915379</td>\n",
       "      <td>0.257325</td>\n",
       "      <td>-4.528157</td>\n",
       "      <td>-4.802762</td>\n",
       "      <td>...</td>\n",
       "      <td>2.348852</td>\n",
       "      <td>0.694605</td>\n",
       "      <td>0.879653</td>\n",
       "      <td>-4.140651</td>\n",
       "      <td>-0.308508</td>\n",
       "      <td>3.332325</td>\n",
       "      <td>0.210760</td>\n",
       "      <td>0.428892</td>\n",
       "      <td>840.767822</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.445677</td>\n",
       "      <td>-1.580400</td>\n",
       "      <td>-1.838960</td>\n",
       "      <td>-0.184744</td>\n",
       "      <td>-0.269978</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>0.892776</td>\n",
       "      <td>-0.455520</td>\n",
       "      <td>-0.673299</td>\n",
       "      <td>-0.362197</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089707</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.446814</td>\n",
       "      <td>-1.610541</td>\n",
       "      <td>-0.219919</td>\n",
       "      <td>1.188977</td>\n",
       "      <td>0.327488</td>\n",
       "      <td>0.166892</td>\n",
       "      <td>399.517303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.884188</td>\n",
       "      <td>3.956302</td>\n",
       "      <td>-7.764510</td>\n",
       "      <td>3.622705</td>\n",
       "      <td>-5.924164</td>\n",
       "      <td>-2.216120</td>\n",
       "      <td>-6.813423</td>\n",
       "      <td>3.795501</td>\n",
       "      <td>-4.827262</td>\n",
       "      <td>-8.016307</td>\n",
       "      <td>...</td>\n",
       "      <td>1.751755</td>\n",
       "      <td>-0.210861</td>\n",
       "      <td>-0.534365</td>\n",
       "      <td>-0.878219</td>\n",
       "      <td>0.268397</td>\n",
       "      <td>0.116465</td>\n",
       "      <td>-0.040222</td>\n",
       "      <td>-0.369845</td>\n",
       "      <td>80.286560</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -5.776999  3.268421 -5.375220  4.764702 -4.173685 -1.467518 -6.940997   \n",
       "1 -0.401826 -3.901563 -1.627244 -1.415839  1.568214 -0.209140  2.603787   \n",
       "2 -2.904875  1.227296 -8.476022  2.107618 -4.752575 -0.844691 -0.915379   \n",
       "3 -0.445677 -1.580400 -1.838960 -0.184744 -0.269978  0.007846  0.892776   \n",
       "4 -7.884188  3.956302 -7.764510  3.622705 -5.924164 -2.216120 -6.813423   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  2.625346 -4.231784 -7.443864  ...  1.282930 -0.091298 -0.290909 -0.760151   \n",
       "1 -1.345410 -0.239516  1.843090  ...  1.041632  0.432413  0.311427 -2.418743   \n",
       "2  0.257325 -4.528157 -4.802762  ...  2.348852  0.694605  0.879653 -4.140651   \n",
       "3 -0.455520 -0.673299 -0.362197  ...  1.089707  0.744048  0.446814 -1.610541   \n",
       "4  3.795501 -4.827262 -8.016307  ...  1.751755 -0.210861 -0.534365 -0.878219   \n",
       "\n",
       "        V25       V26       V27       V28      Amount  Class  \n",
       "0  0.119505  0.233282  0.801211 -0.007126   -0.711648    1.0  \n",
       "1 -0.454784  1.797837  0.206162 -0.010513  602.939148    1.0  \n",
       "2 -0.308508  3.332325  0.210760  0.428892  840.767822    1.0  \n",
       "3 -0.219919  1.188977  0.327488  0.166892  399.517303    1.0  \n",
       "4  0.268397  0.116465 -0.040222 -0.369845   80.286560    1.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generatedData = pd.DataFrame(b, columns = feature_cols + label_col)\n",
    "df_generatedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(generatedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (50000000, 30), indices imply (30, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 1691\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (50000000, 30), indices imply (30, 30)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ec9e3aee52fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_testtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 424\u001b[0;31m                                    copy=copy)\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[0;32m-> 1691\u001b[0;31m         passed, implied))\n\u001b[0m\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (50000000, 30), indices imply (30, 30)"
     ]
    }
   ],
   "source": [
    "df_testtest = pd.DataFrame(a.reshape(-1,30), feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f4113803a81b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneratedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   6679\u001b[0m                 \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6680\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6681\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6682\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6683\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                     mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 451\u001b[0;31m                                        copy=copy)\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must pass 2-d input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "train = train.append(df_testtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amount         0\n",
       "Class     455690\n",
       "V1             0\n",
       "V10            0\n",
       "V11            0\n",
       "V12            0\n",
       "V13            0\n",
       "V14            0\n",
       "V15            0\n",
       "V16            0\n",
       "V17            0\n",
       "V18            0\n",
       "V19            0\n",
       "V2             0\n",
       "V20            0\n",
       "V21            0\n",
       "V22            0\n",
       "V23            0\n",
       "V24            0\n",
       "V25            0\n",
       "V26            0\n",
       "V27            0\n",
       "V28            0\n",
       "V3             0\n",
       "V4             0\n",
       "V5             0\n",
       "V6             0\n",
       "V7             0\n",
       "V8             0\n",
       "V9             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3c6f4764b43d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Class'"
     ]
    }
   ],
   "source": [
    "train_y = train.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop('Class', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4cf08b93ce37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "train_y = train_y.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8d6f189aa487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n\u001b[1;32m      2\u001b[0m                               random_state=42)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                              random_state=42)\n",
    "model = clf.fit(train_X, train_y)\n",
    "preds = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "dtrain = xgb.DMatrix(train_X, train_y, feature_names=feature_cols)\n",
    "dtest = xgb.DMatrix(test_X, test_y, feature_names=feature_cols)\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "param = {\n",
    "        'max_depth':5, \n",
    "        'eta':0.3, \n",
    "        'verbosity': 1, \n",
    "        'objective':'binary:logistic', \n",
    "        'eval_metric': 'auc', \n",
    "        'seed': 42\n",
    "        }\n",
    "\n",
    "model = xgb.train(param, dtrain, num_boost_round=20)\n",
    "# make prediction\n",
    "preds = model.predict(dtest)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Time elapsed to train: ', elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---' * 45)\n",
    "print('XGBoost ROC/AUC: {:.6f}'.format(roc_auc_score(test_y, preds)))\n",
    "print('Recall Score: {:.6f}'.format(recall_score(test_y, preds)))\n",
    "print('Precision Score: {:.6f}'.format(precision_score(test_y, preds)))\n",
    "print('F1 Score: {:.6f}'.format(f1_score(test_y, preds)))\n",
    "print('Accuracy Score: {:.6f}'.format(accuracy_score(test_y, preds)))\n",
    "print('---' * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
